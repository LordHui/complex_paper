{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifest generator for MNIST-like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train for $30-60-30$ with various kl-div coefficients and the following weighting schemes:\n",
    "* sum of size-average kl-divs, i.e. average penalty from each layer\n",
    "* sum of sums of kl-divs, i.e. consistent with theory\n",
    "\n",
    "**NB** we use batch averaged target loss and **do not** multiply\n",
    "by the number of samples in the dataset (for fp arithmetic stability)\n",
    "-- hence in the sum kl-div case the largest coefficient must be\n",
    "$\\tfrac1{\\text{n_samples}}$\n",
    "\n",
    "$$\n",
    "\\frac1N \\widehat{\\mathcal{L}}_{\\text{sgvb}}\n",
    "    = \\widehat{\\mathbb{E}}_{z\\sim B}\n",
    "    \\mathbb{E}_{\\omega \\sim q_\\omega} \\log p(z\\mid \\omega)\n",
    "    - \\frac1N \\mathbb{E}_{\\omega \\sim q_\\omega} \\log\\frac{q_\\omega(\\omega)}{\\pi(\\omega)}\n",
    "\\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mnist-like dataset:\n",
    "  * MNIST, KMNIST, Fashion MNIST, EMNIST-Letters\n",
    "    * emnist has 26 outputs, others - 10\n",
    "\n",
    "* Feature-model\n",
    "  * real-real: Raw, `.real.*` with `n_inputs=1`\n",
    "  * cplx-real: Fourier, `.real.*` with `n_inputs=2`\n",
    "\n",
    "  * real-cplx: Raw, `.cplx.*` with `n_inputs=1` needs to `upcast real to Cplx`\n",
    "  * cplx-cplx: Fourier, `.cplx.*` with `n_inputs=1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load default config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pkg_resources import resource_stream\n",
    "\n",
    "with resource_stream(\"cplxpaper.mnist\", \"template.json\") as fin:\n",
    "    options = json.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the main template:\n",
    "* reset roots\n",
    "* clear model definitions\n",
    "* specify restarts and grad clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.auto.parameter_grid import get_params, set_params, special_params\n",
    "\n",
    "experiment_folder = os.path.expanduser(\"~/Github/complex_paper/experiments/mnist/data\")\n",
    "\n",
    "options = set_params(options, **{\n",
    "    # entirely reset datasets\n",
    "    \"datasets\": {\n",
    "        \"train\": {\"root\": experiment_folder,},\n",
    "        \"test\": {\"root\": experiment_folder,},\n",
    "    },\n",
    "    # by default use 10k train sample size\n",
    "    \"datasets__train__train_size\": 10000,\n",
    "\n",
    "    # attach feeds to the newly defined datasts\n",
    "    \"feeds__train__dataset\": \"train\",\n",
    "    \"feeds__train__batch_size\": 128,\n",
    "    \"feeds__train__pin_memory\": False,\n",
    "    \"feeds__test__dataset\": \"test\",\n",
    "    \"feeds__test__pin_memory\": False,\n",
    "\n",
    "    # specify state inheritance\n",
    "    \"stages__sparsify__restart\": False,\n",
    "    \"stages__sparsify__reset\": False,\n",
    "    \"stages__fine-tune__restart\": True,\n",
    "    \"stages__fine-tune__reset\": False,  # 2020-01-03 used to be True\n",
    "\n",
    "    # L2 clip gradients: seems to be always better to do so.\n",
    "    \"stages__dense__grad_clip\": 0.5,\n",
    "    \"stages__sparsify__grad_clip\": 0.5,\n",
    "    \"stages__fine-tune__grad_clip\": 0.5,\n",
    "\n",
    "    # train 40-75-40\n",
    "    \"stages__dense__n_epochs\": 40,\n",
    "    \"stages__sparsify__n_epochs\": 75,\n",
    "    \"stages__fine-tune__n_epochs\": 40,\n",
    "\n",
    "    # clean models\n",
    "    \"model\": {},\n",
    "    \"stages__dense__model\": {},\n",
    "    \"stages__sparsify__model\": {},\n",
    "    \"stages__fine-tune__model\": {},\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample some random seeds for train splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0x7fff_ffff, size=(13,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No `123`, `0xdeadc0de` or `42` bullshit!\n",
    "Pick opaque random seed from `np.randint` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.mnist import dataset as mnist_like\n",
    "\n",
    "datasets = {\n",
    "    \"mnist\": {\n",
    "        \"datasets__train__random_state\": 1_641_730_374,\n",
    "        \"datasets__train__cls\": str(mnist_like.MNIST_Train),\n",
    "        \"datasets__test__cls\": str(mnist_like.MNIST_Test),\n",
    "        \"model__n_outputs\": 10,\n",
    "    },\n",
    "    \"kmnist\": {\n",
    "        \"datasets__train__random_state\": 102_048_205,\n",
    "        \"datasets__train__cls\": str(mnist_like.KMNIST_Train), \n",
    "        \"datasets__test__cls\": str(mnist_like.KMNIST_Test),\n",
    "        \"model__n_outputs\": 10,\n",
    "    },\n",
    "    \"fashion-mnist\": {\n",
    "        \"datasets__train__random_state\": 1_526_761_432,\n",
    "        \"datasets__train__cls\": str(mnist_like.FashionMNIST_Train), \n",
    "        \"datasets__test__cls\": str(mnist_like.FashionMNIST_Test),\n",
    "        \"model__n_outputs\": 10,\n",
    "    },\n",
    "    \"emnist\": {\n",
    "        \"datasets__train__random_state\": 605_446_338,\n",
    "        \"datasets__train__cls\": str(mnist_like.EMNIST_Letters_Train), \n",
    "        \"datasets__test__cls\": str(mnist_like.EMNIST_Letters_Test),\n",
    "        \"model__n_outputs\": 26,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KL divergence term structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify how kl-div term within each layer are reduced and the base multiplier $C$ of the term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_kl_div = {\n",
    "    \"mean\": {\n",
    "        \"objective_terms__kl_div__reduction\": \"mean\",\n",
    "        \"objective_terms__kl_div__coef\": 1.0,\n",
    "    },\n",
    "    \"sum\": {\n",
    "        \"objective_terms__kl_div__reduction\": \"sum\",\n",
    "        \"objective_terms__kl_div__coef\": 1e-4,  # 1 / n_samples (10k above)\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean yields ELBO\n",
    "$$\n",
    "    \\sum_i \\mathbb{E}_{W \\sim q_W} \\log p(z_i\\,\\mid W)\n",
    "    - \\lambda \\sum_k \\frac{C}{\\lvert W_k\\rvert}\n",
    "        \\sum_{w\\in W_k} \\mathbb{E}_{w\\sim q_w} \\log \\frac{q_w(w)}{\\pi_w(w)}\n",
    "\\,.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sum yields\n",
    "$$\n",
    "    \\sum_i \\mathbb{E}_{W \\sim q_W} \\log p(z_i\\,\\mid W)\n",
    "    - \\lambda C \\sum_k \\sum_{w\\in W_k} \\mathbb{E}_{w\\sim q_w} \\log \\frac{q_w(w)}{\\pi_w(w)}\n",
    "\\,.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\mathbb{R}$-Model stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.mnist.models import real\n",
    "\n",
    "real_model_stages = {\n",
    "    \"twolayerdense\": {\n",
    "        \"model__cls\": [str(real.TwoLayerDenseModel),],\n",
    "        \"stages__sparsify__model__cls\": [str(real.TwoLayerDenseModelARD),],\n",
    "        \"stages__fine-tune__model__cls\": [str(real.TwoLayerDenseModelMasked),],\n",
    "    },\n",
    "#     \"simpledense\": {  # SKIP\n",
    "#         \"model__cls\": [str(real.SimpleDenseModel),],\n",
    "#         \"stages__sparsify__model__cls\": [str(real.SimpleDenseModelARD),],\n",
    "#         \"stages__fine-tune__model__cls\": [str(real.SimpleDenseModelMasked),],\n",
    "#     },\n",
    "    \"simpleconv\": {\n",
    "        \"model__cls\": [str(real.SimpleConvModel),],\n",
    "        \"stages__sparsify__model__cls\": [str(real.SimpleConvModelARD),],\n",
    "        \"stages__fine-tune__model__cls\": [str(real.SimpleConvModelMasked),],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\mathbb{C}$-model stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cplxpaper.mnist.models.complex as cplx\n",
    "\n",
    "cplx_model_stages = {\n",
    "    \"twolayerdense\": {\n",
    "        \"model__cls\": [str(cplx.TwoLayerDenseModel),],\n",
    "        \"stages__sparsify__model__cls\": [str(cplx.TwoLayerDenseModelARD),],\n",
    "        \"stages__fine-tune__model__cls\": [str(cplx.TwoLayerDenseModelMasked),],\n",
    "    },\n",
    "#     \"simpledense\": {  # SKIP\n",
    "#         \"model__cls\": [str(cplx.SimpleDenseModel),],\n",
    "#         \"stages__sparsify__model__cls\": [str(cplx.SimpleDenseModelARD),],\n",
    "#         \"stages__fine-tune__model__cls\": [str(cplx.SimpleDenseModelMasked),],\n",
    "#     },\n",
    "    \"simpleconv\": {\n",
    "        \"model__cls\": [str(cplx.SimpleConvModel),],\n",
    "        \"stages__sparsify__model__cls\": [str(cplx.SimpleConvModelARD),],\n",
    "        \"stages__fine-tune__model__cls\": [str(cplx.SimpleConvModelMasked),],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Admissible feature-model pairings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.auto import feeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairings for $\\mathbb{R}$-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_real = {\n",
    "    \"real\": {\n",
    "        \"features\": [{\"cls\": str(feeds.FeedRawFeatures),}],\n",
    "        \"model__n_inputs\": [1],\n",
    "        # \"model__upcast\": [True],  # not applicable to real models\n",
    "    },\n",
    "#     \"cplx-fft-abs\": {  # SKIP\n",
    "#         \"features\": [{\n",
    "#             \"cls\": str(feeds.FeedFourierFeatures),\n",
    "#             \"signal_ndim\": 2, \"shift\": True, \"cplx\": False,\n",
    "#         }],\n",
    "#         \"model__n_inputs\": [1],\n",
    "#         # \"model__upcast\": [True],  # not applicable to real models\n",
    "#     },\n",
    "    \"cplx-fft-raw\": {\n",
    "        \"features\": [{\n",
    "            \"cls\": str(feeds.FeedFourierFeatures),\n",
    "            \"signal_ndim\": 2, \"shift\": True, \"cplx\": True,\n",
    "        }],\n",
    "        \"model__n_inputs\": [2],\n",
    "        # \"model__upcast\": [False],  # not applicable to real models\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairings for $\\mathbb{C}$-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cplx = {\n",
    "    \"real\": {\n",
    "        \"features\": [{\"cls\": str(feeds.FeedRawFeatures),}],\n",
    "        \"model__n_inputs\": [1],\n",
    "        \"model__upcast\": [True],\n",
    "    },\n",
    "#     \"cplx-fft-abs\": {  # SKIP\n",
    "#         \"features\": [{\n",
    "#             \"cls\": str(feeds.FeedFourierFeatures),\n",
    "#             \"signal_ndim\": 2, \"shift\": True, \"cplx\": False,\n",
    "#         }],\n",
    "#         \"model__n_inputs\": [1],\n",
    "#         \"model__upcast\": [True],\n",
    "#     },\n",
    "    \"cplx-fft-raw\": {\n",
    "        \"features\": [{\n",
    "            \"cls\": str(feeds.FeedFourierFeatures),\n",
    "            \"signal_ndim\": 2, \"shift\": True, \"cplx\": True,\n",
    "        }],\n",
    "        \"model__n_inputs\": [1],\n",
    "        \"model__upcast\": [False],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_stages = {\"real\": {}, \"cplx\": {}}\n",
    "for f, m in product(features_real, real_model_stages):\n",
    "    features_stages[\"real\"][f, m] = {\n",
    "        **features_real[f],\n",
    "        **real_model_stages[m]\n",
    "    }\n",
    "\n",
    "for f, m in product(features_cplx, cplx_model_stages):\n",
    "    features_stages[\"cplx\"][f, m] = {\n",
    "        **features_cplx[f],\n",
    "        **cplx_model_stages[m]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of experiments: mnist-like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL-divergence term $\\lambda$ settings -- directly affects sparsification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_divs = np.unique(np.r_[\n",
    "    1.0 * np.logspace(-7, -2, 6),\n",
    "    3.3 * np.logspace(-7, -2, 6),\n",
    "    6.6 * np.logspace(-7, -2, 6),\n",
    "    1.0 * np.linspace(0.1, 1, 10)\n",
    "])\n",
    "\n",
    "len(kl_divs), kl_divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_grid = {\n",
    "    # 5 full replications of the same experiment\n",
    "    \"n_copy\": [*range(5)],\n",
    "\n",
    "    # kl-div weights come from a moderately sized grid\n",
    "    \"stages__sparsify__objective__kl_div\": kl_divs,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5*21 = 105 base experiments per setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "grids = {}\n",
    "for k, d in product(objective_kl_div, datasets):\n",
    "    local = copy.deepcopy(options)\n",
    "    grids[k, d] = set_params(\n",
    "        local, **datasets[d], **objective_kl_div[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from cplxpaper.auto.utils import get_class\n",
    "\n",
    "base_folder = os.path.abspath(\"./grids\")\n",
    "assert os.path.exists(base_folder) and os.path.isdir(base_folder)\n",
    "\n",
    "\n",
    "for key, settings in grids.items():\n",
    "    folder = os.path.join(base_folder, \"__\".join(key))\n",
    "    os.makedirs(folder)\n",
    "\n",
    "    for kind, details in features_stages.items():\n",
    "        for (fea, mdl), param in details.items():\n",
    "            pargrid = ParameterGrid([{**base_grid, **param}])\n",
    "            for i, par in enumerate(tqdm.tqdm(pargrid)):\n",
    "                par, special = special_params(**par)\n",
    "                assert not special\n",
    "\n",
    "                local = set_params(copy.deepcopy(settings), **par, device=None)\n",
    "                n_copy = local.pop(\"n_copy\")\n",
    "\n",
    "                # format the name\n",
    "                manifest = f\"{kind}__{mdl}__{fea}__{n_copy}__{i:04d}.json\"\n",
    "                filename = os.path.join(folder, manifest)\n",
    "                json.dump(local, open(filename, \"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from cplxpaper.auto.utils import get_class\n",
    "\n",
    "for i, par in enumerate(tqdm.tqdm(grid)):\n",
    "    par, special = special_params(**par)\n",
    "    assert not special\n",
    "\n",
    "    local = set_params(copy.deepcopy(options), **par, device=None)\n",
    "    n_copy = local.pop(\"n_copy\")\n",
    "\n",
    "    # format the name\n",
    "    dataset = get_class(local[\"datasets\"][\"test\"][\"cls\"]).__name__\n",
    "    dataset = dataset.rsplit(\"_\", 1)[0]\n",
    "    kind = \"cplx\" if local[\"features\"].get(\"signal_ndim\", 1) == 2 else \"real\"\n",
    "    model = get_class(local[\"model\"][\"cls\"]).__name__\n",
    "    \n",
    "    manifest = f\"{dataset}-{kind}-{model}-{n_copy} {i:04d}.json\"\n",
    "    filename = os.path.join(folder, manifest)\n",
    "    json.dump(local, open(filename, \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
