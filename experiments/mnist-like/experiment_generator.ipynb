{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manifest generator for MNIST-like : real vs complex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train for $40-75-40$ with various kl-div coefficients and the following lr-scheduling scheme:\n",
    "* `1e-3` for epochs 0..9, `1e-4` for `10+` (as in Trabelsi et al.)\n",
    "\n",
    "\n",
    "**NB** we use batch averaged target loss and **do not** multiply\n",
    "by the number of samples in the dataset (for fp arithmetic stability)\n",
    "-- hence in the sum kl-div case the largest coefficient should be\n",
    "$\\tfrac1{\\text{n_samples}}$\n",
    "\n",
    "$$\n",
    "\\frac1N \\widehat{\\mathcal{L}}_{\\text{sgvb}}\n",
    "    = \\widehat{\\mathbb{E}}_{z\\sim B}\n",
    "    \\mathbb{E}_{\\omega \\sim q_\\omega} \\log p(z\\mid \\omega)\n",
    "    - \\frac1N \\mathbb{E}_{\\omega \\sim q_\\omega} \\log\\frac{q_\\omega(\\omega)}{\\pi(\\omega)}\n",
    "\\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layer-size averaged ELBO undercompresses and is inconsistent with theory:\n",
    "$$\n",
    "    \\sum_i \\mathbb{E}_{W \\sim q_W} \\log p(z_i\\,\\mid W)\n",
    "    - \\lambda \\sum_k \\frac{C}{\\lvert W_k\\rvert}\n",
    "        \\sum_{w\\in W_k} \\mathbb{E}_{w\\sim q_w} \\log \\frac{q_w(w)}{\\pi_w(w)}\n",
    "\\,. $$\n",
    "\n",
    "Sum is consistent and\n",
    "$$\n",
    "    \\sum_i \\mathbb{E}_{W \\sim q_W} \\log p(z_i\\,\\mid W)\n",
    "    - \\lambda C \\sum_k \\sum_{w\\in W_k} \\mathbb{E}_{w\\sim q_w} \\log \\frac{q_w(w)}{\\pi_w(w)}\n",
    "\\,.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Mnist-like dataset:\n",
    "  * MNIST, KMNIST, Fashion MNIST, EMNIST-Letters\n",
    "    * emnist has 26 outputs, others - 10\n",
    "\n",
    "* Feature-model\n",
    "  * real-real: Raw, `.real.*` with `n_inputs=1`\n",
    "  * cplx-real: Fourier, `.real.*` with `n_inputs=2`\n",
    "\n",
    "  * real-cplx: Raw, `.cplx.*` with `n_inputs=1` needs to `upcast real to Cplx`\n",
    "  * cplx-cplx: Fourier, `.cplx.*` with `n_inputs=1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load default config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pkg_resources import resource_stream\n",
    "\n",
    "with resource_stream(\"cplxpaper.mnist\", \"template.json\") as fin:\n",
    "    options = json.load(fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample some random seeds for train splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0x7fff_ffff, size=(13,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No `123`, `0xdeadc0de` or `42` bullshit!\n",
    "Pick opaque random seed from `np.randint` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.mnist import dataset\n",
    "\n",
    "dataset_variety = {\n",
    "    \"mnist\": {\n",
    "        \"datasets__train__random_state\": [1_641_730_374],\n",
    "        \"datasets__train__cls\": [str(dataset.MNIST_Train)],\n",
    "        \"datasets__test__cls\": [str(dataset.MNIST_Test)],\n",
    "        \"model__n_outputs\": [10],\n",
    "    },\n",
    "    \"kmnist\": {\n",
    "        \"datasets__train__random_state\": [102_048_205],\n",
    "        \"datasets__train__cls\": [str(dataset.KMNIST_Train)],\n",
    "        \"datasets__test__cls\": [str(dataset.KMNIST_Test)],\n",
    "        \"model__n_outputs\": [10],\n",
    "    },\n",
    "    \"fashion-mnist\": {\n",
    "        \"datasets__train__random_state\": [1_526_761_432],\n",
    "        \"datasets__train__cls\": [str(dataset.FashionMNIST_Train)],\n",
    "        \"datasets__test__cls\": [str(dataset.FashionMNIST_Test)],\n",
    "        \"model__n_outputs\": [10],\n",
    "    },\n",
    "    \"emnist-letters\": {\n",
    "        \"datasets__train__random_state\": [605_446_338],\n",
    "        \"datasets__train__cls\": [str(dataset.EMNIST_Letters_Train)],\n",
    "        \"datasets__test__cls\": [str(dataset.EMNIST_Letters_Test)],\n",
    "        \"model__n_outputs\": [26],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enumerate all possbile model `combinations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.mnist import models\n",
    "from itertools import product, chain\n",
    "\n",
    "model_combinations = {\n",
    "    \"real\": [*chain(product([\n",
    "            models.real.SimpleConvModel\n",
    "        ], [\n",
    "            models.real.SimpleConvModelARD, models.real.SimpleConvModelVD\n",
    "        ], [\n",
    "            models.real.SimpleConvModelMasked\n",
    "        ]), product([\n",
    "            models.real.TwoLayerDenseModel\n",
    "        ], [\n",
    "            models.real.TwoLayerDenseModelARD, models.real.TwoLayerDenseModelVD\n",
    "        ], [\n",
    "            models.real.TwoLayerDenseModelMasked\n",
    "        ])\n",
    "    )],\n",
    "    \"complex\": [*chain(product([\n",
    "            models.complex.SimpleConvModel\n",
    "        ], [\n",
    "            models.complex.SimpleConvModelARD, models.complex.SimpleConvModelVD\n",
    "        ], [\n",
    "            models.complex.SimpleConvModelMasked\n",
    "        ]), product([\n",
    "            models.complex.TwoLayerDenseModel\n",
    "        ], [\n",
    "            models.complex.TwoLayerDenseModelARD, models.complex.TwoLayerDenseModelVD\n",
    "        ], [\n",
    "            models.complex.TwoLayerDenseModelMasked\n",
    "        ])\n",
    "    )],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_variety = {}\n",
    "\n",
    "for name, combinations in model_combinations.items():\n",
    "    for models in combinations:\n",
    "        m_dense, m_sparsify, m_masked = map(str, models)\n",
    "        model_variety.setdefault(name, []).append({\n",
    "            \"stages__dense__model__cls\": [m_dense],\n",
    "            \"stages__sparsify__model__cls\": [m_sparsify],\n",
    "            \"stages__fine-tune__model__cls\": [m_masked],\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update the template with correct data specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options.update({\n",
    "    \"datasets\": {\n",
    "        \"train\": {\n",
    "            \"cls\": None,\n",
    "            \"root\": '/home/ivan.nazarov/Github/complex_paper/experiments/mnist-like/data',\n",
    "            \"random_state\": None,\n",
    "\n",
    "            # by default use 10k train sample size\n",
    "            \"train_size\": 10000\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"cls\": None,\n",
    "            \"root\": '/home/ivan.nazarov/Github/complex_paper/experiments/mnist-like/data'\n",
    "        },\n",
    "    },\n",
    "    'features': {\n",
    "        \"cls\": None\n",
    "    },\n",
    "    \"feeds\": {\n",
    "        'train': {\n",
    "            'cls': \"<class 'torch.utils.data.dataloader.DataLoader'>\",\n",
    "            'dataset': 'train',\n",
    "            'batch_size': 128,\n",
    "            'shuffle': True,\n",
    "            'pin_memory': False,\n",
    "            'n_batches': -1\n",
    "        },\n",
    "        'test': {\n",
    "            'cls': \"<class 'torch.utils.data.dataloader.DataLoader'>\",\n",
    "            'dataset': 'test',\n",
    "            'batch_size': 128,\n",
    "            'shuffle': False,\n",
    "            'pin_memory': False,\n",
    "            'n_batches': -1\n",
    "        }\n",
    "    },\n",
    "    \"scorers\": {},  # we shall score models when building a report\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the main template:\n",
    "* reset roots\n",
    "* clear model definitions\n",
    "* specify restarts and grad clips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.auto.parameter_grid import get_params, set_params, special_params\n",
    "\n",
    "options = set_params(options, **{\n",
    "    \"threshold\": -0.5,  # we use -1/2 for reasons outlined in the text\n",
    "\n",
    "    \"objective_terms__kl_div__reduction\": \"sum\",\n",
    "    \"objective_terms__kl_div__coef\": 1e-4,  # 1 / 10k\n",
    "\n",
    "    # specify state inheritance\n",
    "    \"stages__sparsify__restart\": False,\n",
    "    \"stages__sparsify__reset\": False,\n",
    "\n",
    "    \"stages__fine-tune__restart\": True,  # restart the optimizer\n",
    "    \"stages__fine-tune__reset\": False,\n",
    "\n",
    "    # L2 clip gradients: seems to be always better to do so.\n",
    "    \"stages__dense__grad_clip\": 0.5,\n",
    "    \"stages__sparsify__grad_clip\": 0.5,\n",
    "    \"stages__fine-tune__grad_clip\": 0.5,\n",
    "\n",
    "    # train 40-75-40\n",
    "    \"stages__dense__n_epochs\": 40,\n",
    "    \"stages__sparsify__n_epochs\": 75,\n",
    "    \"stages__fine-tune__n_epochs\": 40,\n",
    "\n",
    "# radish-on-a-plate is decreasing the lr too fast\n",
    "#     \"stages__dense__lr_scheduler__cls\": \"<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\",\n",
    "#     \"stages__sparsify__lr_scheduler__cls\": \"<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\",\n",
    "#     \"stages__fine-tune__lr_scheduler__cls\": \"<class 'torch.optim.lr_scheduler.ReduceLROnPlateau'>\",\n",
    "\n",
    "    # in the original run I used this scheduler and it yielded the compression results\n",
    "    \"stages__dense__lr_scheduler__cls\": \"<class 'cplxpaper.musicnet.lr_scheduler.Trabelsi2017LRSchedule'>\",\n",
    "    \"stages__sparsify__lr_scheduler__cls\": \"<class 'cplxpaper.musicnet.lr_scheduler.Trabelsi2017LRSchedule'>\",\n",
    "    \"stages__fine-tune__lr_scheduler__cls\": \"<class 'cplxpaper.musicnet.lr_scheduler.Trabelsi2017LRSchedule'>\",\n",
    "\n",
    "    # clean models\n",
    "    \"model\": {},\n",
    "    \"stages__dense__model\": {},\n",
    "    \"stages__sparsify__model\": {},\n",
    "    \"stages__fine-tune__model\": {},\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KL-divergence coeffcient $C$ settings -- directly affects sparsification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_grid = {\n",
    "    # binary ratio grid scaled by \\tfrac3{2^k} for k = -19..-2\n",
    "    \"stages__sparsify__objective__kl_div\":\n",
    "        1.5 * np.logspace(-19, -1, base=2, num=37),\n",
    "\n",
    "    # use only one threshold for higher sparsity at the cost of worse performance\n",
    "    \"threshold\": [-0.5],\n",
    "}\n",
    "\n",
    "# np.unique(np.r_[\n",
    "#     1.0 * np.logspace(-7, -2, 6),\n",
    "#     3.3 * np.logspace(-7, -2, 6),\n",
    "#     6.6 * np.logspace(-7, -2, 6),\n",
    "#     1.0 * np.linspace(0.1, 1, 10)\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, tag = [], \"real-vs-cplx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Halving-doubling: Raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use raw feaures and compare $\\mathbb{R}$ against $\\tfrac12 \\mathbb{C}$, and $\\mathbb{C}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.auto import feeds\n",
    "\n",
    "features = {\n",
    "    \"features__cls\": [str(feeds.FeedRawFeatures),],\n",
    "    \"model__n_inputs\": [1],\n",
    "}\n",
    "for data, data_options in dataset_variety.items():\n",
    "    for model_stages in model_variety[\"real\"]:\n",
    "        grid.append({\n",
    "            \"____name__\": [f\"Full real-valued model on raw {data} 10k\"],\n",
    "            **data_options,\n",
    "            **model_stages,\n",
    "            **features,\n",
    "            \"model__double\": [False],\n",
    "            **base_grid\n",
    "        })\n",
    "\n",
    "    for model_stages in model_variety[\"complex\"]:\n",
    "        grid.append({\n",
    "            \"____name__\": [f\"Halved complex-valued model on raw {data} 10k\"],\n",
    "            **data_options,\n",
    "            **model_stages,\n",
    "            **features,\n",
    "            \"model__half\": [True],\n",
    "            \"model__upcast\": [True],\n",
    "            **base_grid\n",
    "        })\n",
    "\n",
    "    for model_stages in model_variety[\"complex\"]:\n",
    "        grid.append({\n",
    "            \"____name__\": [f\"Full complex-valued model on raw {data} 10k\"],\n",
    "            **data_options,\n",
    "            **model_stages,\n",
    "            **features,\n",
    "            \"model__half\": [False],\n",
    "            \"model__upcast\": [True],\n",
    "            **base_grid\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Halving-doubling: FFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Fourier feaures and compare $2 \\mathbb{R}$ against $\\mathbb{C}$, and $\\mathbb{R}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.auto import feeds\n",
    "\n",
    "features = {\n",
    "    \"features__cls\": [str(feeds.FeedFourierFeatures),],\n",
    "    \"features__cplx\": [True],\n",
    "    \"features__shift\": [True],\n",
    "    \"features__signal_ndim\": [2],\n",
    "}\n",
    "for data, data_options in dataset_variety.items():\n",
    "    for model_stages in model_variety[\"real\"]:\n",
    "        grid.append({\n",
    "            \"____name__\": [f\"Doubled real-valued model on Fourier features of {data} 10k\"],\n",
    "            **data_options,\n",
    "            **model_stages,\n",
    "            **features,\n",
    "            \"model__n_inputs\": [2],\n",
    "            \"model__double\": [True],\n",
    "            **base_grid\n",
    "        })\n",
    "\n",
    "    for model_stages in model_variety[\"complex\"]:\n",
    "        grid.append({\n",
    "            \"____name__\": [f\"Full complex-valued model on Fourier features of {data} 10k\"],\n",
    "            **data_options,\n",
    "            **model_stages,\n",
    "            **features,\n",
    "            \"model__half\": [False],\n",
    "            \"model__upcast\": [False],\n",
    "            **base_grid\n",
    "        })\n",
    "\n",
    "    for model_stages in model_variety[\"real\"]:\n",
    "        grid.append({\n",
    "            \"____name__\": [f\"Full real-valued model on Fourier features of {data} 10k\"],\n",
    "            **data_options,\n",
    "            **model_stages,\n",
    "            **features,\n",
    "            \"model__n_inputs\": [2],\n",
    "            \"model__double\": [False],\n",
    "            **base_grid\n",
    "        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cerate a master folder to house all grid replications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUFFIX = \"-20200213\"\n",
    "\n",
    "base_folder = os.path.normpath(os.path.abspath(f\"./grids{SUFFIX}/\"))\n",
    "os.makedirs(base_folder, exist_ok=False)\n",
    "\n",
    "assert os.path.exists(base_folder) and os.path.isdir(base_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the experiment 5 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_replications = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write experiment manifest en-masse: put each replication in a separate folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "folders = []\n",
    "for replication in range(n_replications):\n",
    "    folder = os.path.join(base_folder, f\"mnist-like__{tag}__{replication:02d}\")\n",
    "    os.makedirs(folder, exist_ok=False)\n",
    "\n",
    "    for exp_no, par in enumerate(tqdm.tqdm(ParameterGrid(grid))):\n",
    "        par, special = special_params(**par)\n",
    "\n",
    "        local = set_params(copy.deepcopy(options), **par, device=None)\n",
    "        local.update(special)\n",
    "\n",
    "        # format the name\n",
    "        filename = os.path.join(folder, f\"experiment__{exp_no:05d}.json\")\n",
    "        json.dump(local, open(filename, \"w\"), indent=2)\n",
    "    \n",
    "    folders.append(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a bash script for this grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stat\n",
    "\n",
    "devspec = \"\"\"--devices \"cuda:0\" \"cuda:1\" \"cuda:2\" \"cuda:3\" --per-device 8\"\"\"\n",
    "cmd_report = f'''python -m cplxpaper.auto.reports {devspec} {{kind}} {{output}} {{paths}}'''\n",
    "\n",
    "bash = os.path.join(base_folder, \"mnist-like.sh\")\n",
    "with open(bash, \"w\") as fout:\n",
    "    # experiment execution\n",
    "    for folder in map(os.path.abspath, folders):\n",
    "        fout.write(f\"\"\"python -m cplxpaper.auto {devspec} \"{folder}\"\\n\"\"\")\n",
    "\n",
    "    # report analysis\n",
    "    paths = '\" \"'.join(map(os.path.abspath, folders))\n",
    "    output = os.path.join(base_folder, \"report__trade-off.pk\")\n",
    "    fout.write(f\"\"\"python -m cplxpaper.auto.reports {devspec} \"trade-off\" \"{output}\" \"{paths}\"\\n\"\"\")\n",
    "\n",
    "# allow exc and keep r/w\n",
    "os.chmod(bash, stat.S_IXUSR | stat.S_IRUSR | stat.S_IWUSR)\n",
    "\n",
    "bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
