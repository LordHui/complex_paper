{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Analysis: MNIST-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully flatten the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.auto.parameter_grid import get_params\n",
    "\n",
    "def get_details(self):\n",
    "    out = dict()\n",
    "    for key in self:\n",
    "        value = self[key]\n",
    "        if isinstance(value, (dict, list, tuple)):\n",
    "            if isinstance(value, (list, tuple)):\n",
    "                value = {f\"[{i}]\": v for i, v in enumerate(value)}\n",
    "                nested = get_details(value).items()\n",
    "                out.update((key + k, val) for k, val in nested)\n",
    "\n",
    "            elif isinstance(value, dict):\n",
    "                nested = get_details(value).items()\n",
    "                out.update((key + '__' + k, val) for k, val in nested)\n",
    "\n",
    "            continue\n",
    "\n",
    "        out[key] = value\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load performance results from each snapshot in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.auto.utils import load_snapshot\n",
    "\n",
    "def from_snapshots(*snapshots):\n",
    "    results, options = {}, {}\n",
    "    for snapshot in sorted(snapshots):\n",
    "        name = os.path.basename(snapshot)\n",
    "        snapshot = load_snapshot(snapshot)\n",
    "\n",
    "        options = snapshot['options']\n",
    "        stage, settings = snapshot['stage']\n",
    "\n",
    "        results[name] = stage, snapshot['performance']\n",
    "\n",
    "    return results, options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load experimnet from its snapshots or from cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "\n",
    "\n",
    "def load_experiment(folder, cache=\"cache.pk\"):\n",
    "    if isinstance(cache, str):\n",
    "        cache = os.path.join(folder, cache)\n",
    "\n",
    "    assert cache is None or isinstance(cache, str)\n",
    "\n",
    "    snapshots = []\n",
    "    folder, _, filenames = next(os.walk(folder))\n",
    "    for filename in sorted(filenames):\n",
    "        if re.match(r\"^\\d+.*\\.gz$\", filename) is not None:\n",
    "            snapshots.append(filename)\n",
    "\n",
    "    # load scorer results from the snapshots or from cache\n",
    "    scores, options = {}, {}\n",
    "    if cache is not None and os.path.exists(cache):\n",
    "        with open(cache, \"rb\") as fin:\n",
    "            scores, options = pickle.load(fin)\n",
    "\n",
    "    # reload from originals af anything is missing (use SHA-digest)\n",
    "    if any(s not in scores for s in snapshots):\n",
    "        snapshots = [os.path.join(folder, s) for s in snapshots]\n",
    "        scores, options = from_snapshots(*snapshots)\n",
    "        if cache is not None:\n",
    "            with open(cache, \"wb\") as fout:\n",
    "                pickle.dump((scores, options), fout)\n",
    "\n",
    "    return scores, options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"./grids/minst-like/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect results and reconstruct the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "grid = defaultdict(set)\n",
    "ignore = {\"__name__\", \"__timestamp__\", \"__version__\", \"device\"}\n",
    "\n",
    "results = []\n",
    "source, experiments, manifests = next(os.walk(source))\n",
    "for experiment in tqdm.tqdm(experiments):\n",
    "    match = re.match(r\"^(?!\\.).*\\s+(\\d+)$\", experiment)\n",
    "    if not match:\n",
    "        continue\n",
    "\n",
    "    expno, = match.groups()\n",
    "\n",
    "    # load scorer results from the snapshots\n",
    "    scores, options = load_experiment(\n",
    "        os.path.join(source, experiment),\n",
    "        cache='cache.pk')\n",
    "\n",
    "    if not options:\n",
    "        continue\n",
    "\n",
    "    flat = get_details(options)\n",
    "    for k, v in flat.items():\n",
    "        if k not in ignore:\n",
    "            grid[k].add(v)\n",
    "\n",
    "    scores = pd.DataFrame.from_dict({\n",
    "        k: v[\"test\"] for k, v in scores.values()\n",
    "    }, orient='index')\n",
    "\n",
    "    results.append((int(expno), scores, flat))\n",
    "\n",
    "# pick all keys which have more than one unique value\n",
    "#  and drop any nested model spec changes\n",
    "grid = [k for k, v in grid.items()\n",
    "        if len(v) > 1 and  \"__model__cls\" not in k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, scores, manifests = zip(*results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{k: opt[k] for k in grid} for opt in manifests]\n",
    "params = pd.DataFrame.from_dict(dict(zip(experiments, params)), orient=\"index\")\n",
    "\n",
    "scores = [score[[\"accuracy\", \"sparsity\"]] for score in tqdm.tqdm(scores)]\n",
    "scores = pd.concat(dict(zip(experiments, scores)), axis=0, names=[\"expno\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scores.unstack(-1)\n",
    "df.columns = df.columns.to_flat_index().map('-'.join)\n",
    "df = params.join(df).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({\n",
    "    \"model__cls\": {\n",
    "        \"<class 'cplxpaper.mnist.models.real.SimpleConvModel'>\": \"real.SimpleConvModel\",\n",
    "        \"<class 'cplxpaper.mnist.models.complex.SimpleConvModel'>\": \"cplx.SimpleConvModel\",\n",
    "        \"<class 'cplxpaper.mnist.models.real.TwoLayerDenseModel'>\": \"real.TwoLayerDenseModel\",\n",
    "        \"<class 'cplxpaper.mnist.models.complex.TwoLayerDenseModel'>\": \"cplx.TwoLayerDenseModel\",\n",
    "        \"<class 'cplxpaper.mnist.models.real.SimpleDenseModel'>\": \"real.SimpleDenseModel\",\n",
    "        \"<class 'cplxpaper.mnist.models.complex.SimpleDenseModel'>\": \"cplx.SimpleDenseModel\",\n",
    "    },\n",
    "    \"features__cls\": {\n",
    "        \"<class 'cplxpaper.auto.feeds.FeedRawFeatures'>\": 'raw',\n",
    "        \"<class 'cplxpaper.auto.feeds.FeedFourierFeatures'>\": 'fourier'\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index([\n",
    "    \"features__cls\", \"model__cls\", \"stages__sparsify__objective__kl_div\", \"index\"\n",
    "], append=False, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.sort_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {}\n",
    "for k, g in df.groupby(axis=0, level=[0, 1]):\n",
    "    g = g.loc[k]\n",
    "    base = g[\"accuracy-dense\"]\n",
    "    curve = g[[\"sparsity-sparsify\", \"accuracy-fine-tune\"]]\n",
    "\n",
    "    curve = curve.mean(level=0).to_numpy()    \n",
    "    order = curve[:, 0].argsort()\n",
    "\n",
    "    summary[k] = (base.mean(), base.std()), curve[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "\n",
    "for name, (dense, curve) in summary.items():\n",
    "    m, s = dense\n",
    "#     pts = ax.scatter(*curve.T, label=name, s=25)\n",
    "#     color = pts.get_facecolor()[0]\n",
    "    spr, acc = curve.T\n",
    "    pts, = ax.semilogy(1-spr, 1-acc, label=name)\n",
    "    color = pts.get_color()\n",
    "\n",
    "    ax.axhspan((1-m)-1.96*s, (1-m)+1.96*s, alpha=0.1, color=color)\n",
    "\n",
    "#     ax.set_yscale(\"log\")\n",
    "#     ax.set_xscale(\"log\");# ax.set_xlim(0.01, 1.5)\n",
    "#     ax.set_xlim(-0.05, 1.05)\n",
    "\n",
    "ax.legend(ncol=2)\n",
    "ax.set_title(\"MNIST\")\n",
    "ax.set_ylabel(\"error\")\n",
    "ax.set_xlabel(\"compression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
