{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Analysis: MNIST-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fully flatten the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.auto.parameter_grid import get_params\n",
    "\n",
    "def get_details(self):\n",
    "    out = dict()\n",
    "    for key in self:\n",
    "        value = self[key]\n",
    "        if isinstance(value, (dict, list, tuple)):\n",
    "            if isinstance(value, (list, tuple)):\n",
    "                value = {f\"[{i}]\": v for i, v in enumerate(value)}\n",
    "                nested = get_details(value).items()\n",
    "                out.update((key + k, val) for k, val in nested)\n",
    "\n",
    "            elif isinstance(value, dict):\n",
    "                nested = get_details(value).items()\n",
    "                out.update((key + '__' + k, val) for k, val in nested)\n",
    "\n",
    "            continue\n",
    "\n",
    "        out[key] = value\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load performance results from each snapshot in the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.auto.utils import load_snapshot\n",
    "\n",
    "def from_snapshots(*snapshots):\n",
    "    results, options = {}, {}\n",
    "    for snapshot in sorted(snapshots):\n",
    "        name = os.path.basename(snapshot)\n",
    "        snapshot = load_snapshot(snapshot)\n",
    "\n",
    "        options = snapshot['options']\n",
    "        stage, settings = snapshot['stage']\n",
    "\n",
    "        results[name] = stage, snapshot['performance']\n",
    "\n",
    "    return results, options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load experiment from its snapshots or from cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "\n",
    "\n",
    "def load_experiment(folder, cache=\"cache.pk\"):\n",
    "    if isinstance(cache, str):\n",
    "        cache = os.path.join(folder, cache)\n",
    "\n",
    "    assert cache is None or isinstance(cache, str)\n",
    "\n",
    "    snapshots = []\n",
    "    folder, _, filenames = next(os.walk(folder))\n",
    "    for filename in sorted(filenames):\n",
    "        if re.match(r\"^\\d+.*\\.gz$\", filename) is not None:\n",
    "            snapshots.append(filename)\n",
    "\n",
    "    # load scorer results from the snapshots or from cache\n",
    "    scores, options = {}, {}\n",
    "    if cache is not None and os.path.exists(cache):\n",
    "        with open(cache, \"rb\") as fin:\n",
    "            scores, options = pickle.load(fin)\n",
    "\n",
    "    # reload from originals if anything is missing (use SHA-digest)\n",
    "    if any(s not in scores for s in snapshots):\n",
    "        snapshots = [os.path.join(folder, s) for s in snapshots]\n",
    "        scores, options = from_snapshots(*snapshots)\n",
    "        if cache is not None:\n",
    "            with open(cache, \"wb\") as fout:\n",
    "                pickle.dump((scores, options), fout)\n",
    "\n",
    "    return scores, options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cache the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"\"\"./grids/sum__fashion-mnist/\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect perfomance grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_summary(scores):\n",
    "    out = {}\n",
    "    for stage, results in scores.values():\n",
    "        # Collect performance metrics..\n",
    "        score = results[\"test\"]\n",
    "\n",
    "        # ... aggregate sparsity and accuracy.\n",
    "        n_zer, n_par = map(sum, zip(*score[\"sparsity\"].values()))\n",
    "        out[stage] = {\"accuracy\": score[\"accuracy\"],\n",
    "                      \"n_zer\": int(n_zer), \"n_par\": int(n_par)}\n",
    "\n",
    "    return pd.DataFrame.from_dict(out, orient='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect results and reconstruct the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "grid = defaultdict(set)\n",
    "ignore = {\"__name__\", \"__timestamp__\", \"__version__\", \"device\"}\n",
    "\n",
    "results = []\n",
    "source, experiments, manifests = next(os.walk(source))\n",
    "for experiment in tqdm.tqdm(experiments):\n",
    "    match = re.match(r\"^(?!\\.).*__\\d+$\", experiment)\n",
    "    if not match:\n",
    "        continue\n",
    "\n",
    "    head, copy, expno = experiment.rsplit(\"__\", 2)\n",
    "\n",
    "    # load scorer results from the snapshots\n",
    "    scores, options = load_experiment(\n",
    "        os.path.join(source, experiment),\n",
    "        cache='cache.pk')\n",
    "\n",
    "    if not options:\n",
    "        continue\n",
    "\n",
    "    flat = get_details(options)\n",
    "    for k, v in flat.items():\n",
    "        if k not in ignore:\n",
    "            grid[k].add(v)\n",
    "\n",
    "    results.append((\n",
    "        experiment,\n",
    "        performance_summary(scores),\n",
    "        flat\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments, scores, manifests = zip(*results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalize the grid variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pick all keys which have more than one unique value\n",
    "#  and drop any nested model spec changes\n",
    "grid = [k for k, v in grid.items()\n",
    "        if len(v) > 1 and  \"__model__cls\" not in k]\n",
    "\n",
    "# upcast is a service variable, which only complex models have\n",
    "#  and it i usually mirrored in `features` settings.\n",
    "grid = [g for g in grid if not g.endswith(\"__upcast\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{k: opt.get(k, None) for k in grid} for opt in manifests]\n",
    "params = pd.DataFrame.from_dict(dict(zip(experiments, params)), orient=\"index\")\n",
    "\n",
    "scores = pd.concat(dict(zip(experiments, scores)),\n",
    "                   axis=0, names=[\"expno\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = scores.unstack(-1)\n",
    "df.columns = df.columns.to_flat_index().map('-'.join)\n",
    "df = params.join(df).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace({\n",
    "    \"model__cls\": {\n",
    "        \"<class 'cplxpaper.mnist.models.real.SimpleConvModel'>\": \"real.SimpleConvModel\",\n",
    "        \"<class 'cplxpaper.mnist.models.complex.SimpleConvModel'>\": \"cplx.SimpleConvModel\",\n",
    "        \"<class 'cplxpaper.mnist.models.real.TwoLayerDenseModel'>\": \"real.TwoLayerDenseModel\",\n",
    "        \"<class 'cplxpaper.mnist.models.complex.TwoLayerDenseModel'>\": \"cplx.TwoLayerDenseModel\",\n",
    "        \"<class 'cplxpaper.mnist.models.real.SimpleDenseModel'>\": \"real.SimpleDenseModel\",\n",
    "        \"<class 'cplxpaper.mnist.models.complex.SimpleDenseModel'>\": \"cplx.SimpleDenseModel\",\n",
    "    },\n",
    "    \"features__cls\": {\n",
    "        \"<class 'cplxpaper.auto.feeds.FeedRawFeatures'>\": 'raw',\n",
    "        \"<class 'cplxpaper.auto.feeds.FeedFourierFeatures'>\": 'fourier'\n",
    "    },\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index([*grid, \"index\"], append=False, drop=True).sort_index(0)\n",
    "main_grid = [g for g in grid if not g.endswith('__kl_div')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {}\n",
    "for k, g in df.groupby(axis=0, level=main_grid):\n",
    "    g = g.loc[k]\n",
    "\n",
    "    acc_before = g[\"accuracy-dense\"].mean(), g[\"accuracy-dense\"].std()\n",
    "    f_acc, n_par, n_zer = g[\"accuracy-fine-tune\"], g[\"n_par-sparsify\"], g[\"n_zer-sparsify\"]\n",
    "\n",
    "    curve = pd.concat([n_zer / n_par, f_acc], axis=1)\n",
    "#     curve = curve.mean(level=0).to_numpy()\n",
    "    curve = curve.to_numpy()\n",
    "    order = curve[:, 0].argsort()\n",
    "\n",
    "    summary[k] = acc_before, curve[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter, FuncFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "\n",
    "for name, (dense, curve) in summary.items():\n",
    "    m, s = dense\n",
    "    spr, acc = curve.T\n",
    "    pts = ax.scatter(1 - spr, acc, label=name, s=15)\n",
    "    color = pts.get_facecolor()[0]\n",
    "#     pts, = ax.plot(1 - spr, acc, label=name)\n",
    "#     color = pts.get_color()\n",
    "    ax.axhspan(m-1.96*s, m+1.96*s, alpha=0.1, color=color)\n",
    "\n",
    "ax.legend(ncol=2)\n",
    "ax.set_title(\"Fashion MNIST\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "\n",
    "ax.set_xlabel(\"% nonzero\")\n",
    "ax.set_xscale(\"log\")\n",
    "\n",
    "ax.xaxis.set_major_formatter(FuncFormatter(lambda x, p: f\"{x:.1%}\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = (n_zer).mean(level=0)\n",
    "s = (n_zer).std(level=0)\n",
    "m.plot()\n",
    "plt.fill_between(m.index, m-1.96*s, m+1.96*s, alpha=0.25)\n",
    "plt.gca().set_xscale(\"log\")\n",
    "\n",
    "plt.twinx()\n",
    "m = (g[\"accuracy-dense\"]).mean(level=0)\n",
    "s = (g[\"accuracy-dense\"]).std(level=0)\n",
    "m.plot(c=\"C1\")\n",
    "plt.fill_between(m.index, m-1.96*s, m+1.96*s, alpha=0.25, color=\"C1\")\n",
    "m = (g[\"accuracy-fine-tune\"]).mean(level=0)\n",
    "s = (g[\"accuracy-fine-tune\"]).std(level=0)\n",
    "m.plot(c=\"C2\")\n",
    "plt.fill_between(m.index, m-1.96*s, m+1.96*s, alpha=0.25, color=\"C2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(n_par - n_zer) / n_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "comp = ((n_par - n_zer) / n_par).to_numpy()\n",
    "plt.gca().set_xscale(\"log\")\n",
    "plt.gca().set_xlim(2e-3, 1.1)\n",
    "plt.scatter(comp, 1-acc_after.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "acc_before.mean(level=0).plot()\n",
    "acc_after.mean(level=0).plot()\n",
    "plt.gca().set_xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "\n",
    "for name, (dense, curve) in summary.items():\n",
    "    m, s = dense\n",
    "#     pts = ax.scatter(*curve.T, label=name, s=25)\n",
    "#     color = pts.get_facecolor()[0]\n",
    "    spr, acc = curve.T\n",
    "    pts, = ax.semilogx(1-spr, acc, label=name)\n",
    "    color = pts.get_color()\n",
    "\n",
    "    ax.axhspan(m-1.96*s, m+1.96*s, alpha=0.1, color=color)\n",
    "\n",
    "#     ax.set_yscale(\"log\")\n",
    "#     ax.set_xscale(\"log\");# ax.set_xlim(0.01, 1.5)\n",
    "#     ax.set_xlim(-0.05, 1.05)\n",
    "\n",
    "ax.legend(ncol=2)\n",
    "ax.set_title(\"MNIST\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_xlabel(\"compression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
