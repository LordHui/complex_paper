{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototype of auto-experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import copy\n",
    "import time\n",
    "import tqdm\n",
    "import json\n",
    "import h5py\n",
    "import importlib\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto import auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"./cplx_09\"\n",
    "!mkdir \"{folder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger()  # \"auto\"\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "fh = logging.FileHandler(os.path.join(folder, \"main.log\"), mode=\"w\")\n",
    "fh.setLevel(logging.DEBUG)\n",
    "\n",
    "fh.setFormatter(logging.Formatter(\n",
    "    \"%(asctime)s - %(name)s - %(levelname)s - %(message)s\"\n",
    "))\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sparsify_masked_weighted_lrsched_cplx.json\", \"r\") as fin:\n",
    "    options = json.load(fin)\n",
    "\n",
    "options['device'] = \"cuda:3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options[\"stages\"].update({\n",
    "    'dense': {\n",
    "        'snapshot': None,\n",
    "        'feed': 'train_trabelsi',\n",
    "        'restart': True,\n",
    "        'n_epochs': 200,\n",
    "        'grad_clip': 0.,\n",
    "        'model': {\n",
    "            'cls': \"<class 'musicnet.complex.base.CplxDeepConvNet'>\"\n",
    "        },\n",
    "        'lr_scheduler': {\n",
    "            'cls': \"<class 'musicnet.trabelsi2017.base.Trabelsi2017LRSchedule'>\"\n",
    "        },\n",
    "        'optimizer': {\n",
    "            'cls': \"<class 'torch.optim.adam.Adam'>\",\n",
    "            'lr': 0.001,\n",
    "            'betas': [0.9, 0.999],\n",
    "            'eps': 1e-08,\n",
    "            'weight_decay': 0,\n",
    "            'amsgrad': False\n",
    "        },\n",
    "        'objective': {\n",
    "            'loss': 1.0,\n",
    "            'kl_div': 0.0\n",
    "        },\n",
    "        'early': {\n",
    "            'feed': 'valid_256',\n",
    "            'patience': 200,\n",
    "            'cooldown': 0,\n",
    "            'rtol': 0,\n",
    "            'atol': 0.01,\n",
    "            'raises': \"<class 'StopIteration'>\"\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options[\"stage-order\"] = [\n",
    "    \"dense\",\n",
    "    'sparsify',\n",
    "    'fine-tune',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del options[\"objective_terms\"][\"loss\"][\"pos_weight\"]\n",
    "options[\"stages\"][\"sparsify\"][\"early\"][\"atol\"] = 2e-2\n",
    "options[\"stages\"][\"fine-tune\"][\"early\"][\"atol\"] = 2e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.run(options, folder, time.strftime(\"%Y%m%d-%H%M%S\"), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.defaults(options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auto.utils import load_snapshot\n",
    "\n",
    "cold = load_snapshot('./cplx_08/1-sparsify 20191220-204057.gz')\n",
    "\n",
    "options = cold[\"options\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placement (dtype / device)\n",
    "options[\"device\"] = \"cuda:3\"\n",
    "devtype = dict(device=torch.device(options[\"device\"]), dtype=torch.float32)\n",
    "\n",
    "# sparsity settings: threshold is log(p / (1 - p)) for p=dropout rate\n",
    "sparsity = dict(hard=True, threshold=options[\"threshold\"])\n",
    "\n",
    "datasets = auto.get_datasets(options[\"dataset\"], options[\"dataset_sources\"])\n",
    "collate_fn = auto.get_collate_fn(options[\"features\"])\n",
    "feeds = auto.get_feeds(datasets, collate_fn, devtype, options[\"feeds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, settings = cold[\"stage\"]\n",
    "state = auto.state_create(options[\"model\"], settings, devtype)\n",
    "\n",
    "state.model.load_state_dict(cold[\"model\"])\n",
    "state.optim.load_state_dict(cold[\"optim\"][\"state\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_terms = auto.get_objective_terms(datasets, options[\"objective_terms\"])\n",
    "\n",
    "formula = settings[\"objective\"]\n",
    "objective = auto.get_objective(objective_terms, formula).to(**devtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxmodule.utils.stats import sparsity, named_sparsity\n",
    "\n",
    "print(f\">>> {sparsity(state.model, threshold=options['threshold']):6.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{name: v for name, v in named_sparsity(state.model, threshold=-0.5)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from auto.objective import named_ard_modules\n",
    "from ipywidgets import widgets\n",
    "\n",
    "log_alphas = {}\n",
    "with torch.no_grad():\n",
    "    for name, submod in named_ard_modules(state.model):\n",
    "        log_alpha = submod.log_alpha.detach().cpu()\n",
    "        log_alphas[name] = log_alpha.numpy()\n",
    "\n",
    "\n",
    "def darker(color, a=0.5):\n",
    "    \"\"\"Adapted from this stackoverflow question_.\n",
    "    .. _question: https://stackoverflow.com/questions/37765197/\n",
    "    \"\"\"\n",
    "    from matplotlib.colors import to_rgb\n",
    "    from colorsys import rgb_to_hls, hls_to_rgb\n",
    "\n",
    "    h, l, s = rgb_to_hls(*to_rgb(color))\n",
    "    return hls_to_rgb(h, max(0, min(a * l, 1)), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if log_alphas:\n",
    "    w_keys = widgets.Dropdown(options=[None, *log_alphas], description=\"Layer\")\n",
    "\n",
    "    @widgets.interact(layer=w_keys)\n",
    "    def plot_hists(layer):\n",
    "        colors = plt.cm.jet(np.linspace(0,1, num=len(log_alphas)))\n",
    "\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(16, 5))\n",
    "        support = np.linspace(-15, 40, num=265)\n",
    "        for (name, log_alpha), col in zip(log_alphas.items(), colors):\n",
    "            if name != layer:\n",
    "                extra = dict(histtype=\"step\", lw=1, zorder=10, alpha=0.25)\n",
    "            else:\n",
    "                extra = dict(histtype=\"bar\", lw=0, alpha=1., zorder=-10)\n",
    "\n",
    "            *_, patches = ax.hist(log_alpha.flat, label=name, bins=51,\n",
    "                                  density=True, **extra, color=col)\n",
    "            if name == layer:\n",
    "                subsample = log_alpha.flat\n",
    "                if len(subsample) > 50000:\n",
    "                    subsample = np.random.choice(subsample, replace=False, size=50000)\n",
    "                density = stats.kde.gaussian_kde(subsample)\n",
    "\n",
    "                color = darker(patches[0].get_facecolor(), 0.75)\n",
    "                ax.plot(support, density(support), c=color, lw=1, zorder=10)\n",
    "\n",
    "\n",
    "        ax.axvline(threshold, c=\"k\")\n",
    "        ax.legend(ncol=2, loc='upper right')\n",
    "        ax.set_ylim(0, 0.5)\n",
    "        ax.set_xlim(-15, 40)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions from slowdown investigation\n",
    "* devtype: add 40 Gb\n",
    "* the length is the cultrip that causes slowdown!\n",
    "    * torch.utils.data.sampler.RandomSample allocates HUGE ram for randint or randperm of 1G sample indices\n",
    "        * plus deallocation!\n",
    "* pinned memory is moderately faster than unpinned\n",
    "* moving to device is very slow\n",
    "\n",
    "* Create a custom random sampler, that preallocates the sample schedule. The dataset is very large, soe we can treat is as almost infinite stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.update(auto.get_datasets(options[\"dataset\"], {\n",
    "#     \"train-1\": {\"filename\": \"./data/musicnet/musicnet_11khz_train.h5\", \"stride\": 1}\n",
    "    \"test-1\": {\"filename\": \"./data/musicnet/musicnet_11khz_test.h5\", \"stride\": 1}\n",
    "#     \"test-32\": {\"filename\": \"./data/musicnet/musicnet_11khz_test.h5\", \"stride\": 32}\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from musicnet.dataset import MusicNetDataLoader\n",
    "\n",
    "feeds.update(auto.get_feeds(datasets, collate_fn, devtype, {\n",
    "#     \"train-512\": {'dataset': 'train-512', 'batch_size': 128, 'shuffle': False},\n",
    "    \"test_trabelsi\": {'cls': str(MusicNetDataLoader), 'dataset': 'test-1', \"n_batches\": 1000},\n",
    "#     \"test-32\": {'dataset': 'test-32', 'batch_size': 512, 'shuffle': False, \"pin_memory\": True}\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings(record=True):  # no need to filter\n",
    "#     feed = auto.wrap_feed(feeds[\"train-512\"], max_iter=-1, **devtype)\n",
    "#     feed = auto.wrap_feed(feeds[\"test_256\"], max_iter=-1, **devtype)\n",
    "    feed = feeds[\"test_trabelsi\"]\n",
    "#     feed = auto.wrap_feed(feeds[\"test-32\"], max_iter=10000, **devtype)\n",
    "    out = auto.evaluate(state.model, tqdm.tqdm(feed), curves=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out[\"pooled_average_precision\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold[\"performance\"]['test_256']['pooled_average_precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 3))\n",
    "\n",
    "ax[0].plot(out[\"average_precision\"], label=f\"AP {np.nanmean(out['average_precision']):.1%}\")\n",
    "ax[0].legend(ncol=2)\n",
    "\n",
    "ax[1].plot(out[\"accuracy\"], label=\"acc.\")\n",
    "ax[1].plot(out[\"precision\"], label=\"P\")\n",
    "ax[1].plot(out[\"recall\"], label=\"R\")\n",
    "ax[1].legend(ncol=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 7))\n",
    "\n",
    "p, r, t = zip(*[prt for k, prt in out[\"ap_curves\"].items() if k != 'pooled'])\n",
    "ax.add_collection(\n",
    "    LineCollection([*map(np.transpose, map(np.stack, zip(r, p)))],\n",
    "                   colors=plt.cm.PuBuGn(np.linspace(0, 1, num=len(p))),\n",
    "                   alpha=0.7)\n",
    ")\n",
    "\n",
    "p, r, t = out[\"ap_curves\"][\"pooled\"]\n",
    "ax.plot(r, p, c=\"k\", lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
