{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MusicNet : compression experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate experiment manifest for the compression-average precision curve for \n",
    "the complex-valued model from Trabelsi et al. (2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import json\n",
    "import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dry_run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to edit nested dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.auto.parameter_grid import special_params\n",
    "\n",
    "from cplxpaper.auto.parameter_grid import get_params, set_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a common tempalte for musicnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pkg_resources\n",
    "\n",
    "with pkg_resources.resource_stream(\"cplxpaper.musicnet\", \"template.json\") as fin:\n",
    "    template = json.load(fin)\n",
    "\n",
    "del template[\"datasets\"][\"musicnet-train-512\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = {\n",
    "    'cls': \"<class 'cplxpaper.musicnet.performance.PooledAveragePrecisionEarlyStopper'>\",\n",
    "    'scorer': 'validation',\n",
    "    'patience': 20,\n",
    "    'cooldown': 0,\n",
    "    'rtol': 0,\n",
    "    'atol': 0.02,\n",
    "    'raises': \"<class 'StopIteration'>\"\n",
    "}\n",
    "\n",
    "template = set_params(template, **{\n",
    "    \"feeds__train__pin_memory\": False,\n",
    "\n",
    "    # dense: 50-75-50\n",
    "    \"stages__dense__n_epochs\": 50,\n",
    "    \"stages__dense__early\": early,\n",
    "\n",
    "    # sparsify: continue from dense\n",
    "    \"stages__sparsify__n_epochs\": 75,\n",
    "    \"stages__sparsify__restart\": False,\n",
    "    \"stages__dense__reset\": False,\n",
    "    \"stages__sparsify__early\": None,\n",
    "\n",
    "    # fine-tune: use vi means and masks from sparsify\n",
    "    \"stages__fine-tune__n_epochs\": 50,\n",
    "    \"stages__fine-tune__restart\": True,\n",
    "    \"stages__fine-tune__reset\": False,\n",
    "    \"stages__fine-tune__early\": early,\n",
    "\n",
    "    # Use bayes-consitent weights\n",
    "    \"objective_terms__kl_div__reduction\": \"sum\",\n",
    "    \"objective_terms__kl_div__coef\": 1e-5,  # corresponds to the number of samples (approximate)\n",
    "                                            #  1k batches x 321 windows\n",
    "\n",
    "    # shifted complex fft\n",
    "    \"features__signal_ndim\": 1,\n",
    "    \"features__cplx\": True,\n",
    "    \"features__shift\": True,\n",
    "    \n",
    "    # paths\n",
    "    \"datasets__musicnet-train__filename\":\n",
    "        os.path.abspath(\"./data/musicnet_11khz_train.h5\"),\n",
    "    \"datasets__musicnet-valid-128__filename\":\n",
    "        os.path.abspath(\"./data/musicnet_11khz_valid.h5\"),\n",
    "    \"datasets__musicnet-test-128__filename\":\n",
    "        os.path.abspath(\"./data/musicnet_11khz_test.h5\"),\n",
    "    \n",
    "    # scorer\n",
    "    \"scorers__validation__threshold\": -0.5,\n",
    "    \"scorers__test__threshold\": -0.5,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Deep convolutional complex-valued network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div = np.unique(np.r_[\n",
    "    0.25 * np.logspace(-4, 0, num=5),\n",
    "    0.50 * np.logspace(-4, 0, num=5),\n",
    "    0.75 * np.logspace(-4, 0, num=5),\n",
    "    1.00 * np.logspace(-5, 0, num=6),\n",
    "])\n",
    "\n",
    "len(kl_div), kl_div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cplx_fine_kl_div = {\n",
    "    \"stages__sparsify__objective__kl_div\": kl_div,\n",
    "    \"n_replication\": [*range(5)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment  2: Deep convolutional complex-valued network\n",
    "\n",
    "Finer kl-div coef grid around the peak of validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_v2 = set(np.r_[\n",
    "    np.linspace(2.5e-3, 1e-2, num=7),\n",
    "    np.linspace(1e-2, 2.5e-2, num=7),\n",
    "]) - set(kl_div)\n",
    "\n",
    "kl_div_v2 = np.unique([*kl_div_v2])\n",
    "\n",
    "len(kl_div_v2), kl_div_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cplx_fine_kl_div_v2 = {\n",
    "    \"stages__sparsify__objective__kl_div\": kl_div_v2,\n",
    "    \"n_replication\": [*range(5)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment  3: fast experiment for VD and ARD\n",
    "\n",
    "Less epochs in `dense`, shorter `sparisfy` phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kl_div_v3 = np.unique(np.r_[\n",
    "    0.25 * np.logspace(-3, -1, num=3),\n",
    "    0.50 * np.logspace(-3, -1, num=3),\n",
    "    0.75 * np.logspace(-3, -1, num=3),\n",
    "    1.00 * np.logspace(-4, -1, num=4),\n",
    "])\n",
    "\n",
    "len(kl_div_v3), kl_div_v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_cplx_fine_kl_div_v3_fast = {\n",
    "    # schedule 12-30-50 epochs\n",
    "    \"stages__dense__n_epochs\": [12],\n",
    "    \"stages__sparsify__n_epochs\": [32],\n",
    "    \"stages__fine-tune__n_epochs\": [50],\n",
    "\n",
    "    # keep early stopper at fine-tune stage only\n",
    "    \"stages__dense__early\": [None],\n",
    "    \"stages__sparsify__early\": [None],\n",
    "    # \"stages__fine-tune__early\": [None],  # keep the stopper\n",
    "    \n",
    "    # use faster lr annealing schedule\n",
    "    \"stages__dense__lr_scheduler\": [{\n",
    "        \"cls\": \"<class 'cplxpaper.musicnet.lr_scheduler.FastStepScheduler'>\"\n",
    "    }],\n",
    "    \"stages__sparsify__lr_scheduler\": [{\n",
    "        \"cls\": \"<class 'cplxpaper.musicnet.lr_scheduler.FastStepScheduler'>\"\n",
    "    }],\n",
    "    \"stages__fine-tune__lr_scheduler\": [{\n",
    "        \"cls\": \"<class 'cplxpaper.musicnet.lr_scheduler.FastStepScheduler'>\"\n",
    "    }],\n",
    "\n",
    "    # select the model\n",
    "    \"model__legacy\": [\n",
    "        False,  # Set to false to correct the sad kernel size mistake\n",
    "                # detected on that fateful day of the 28th of January, 2020.\n",
    "    ],\n",
    "    \"stages__dense__model__cls\": [\n",
    "        \"<class 'cplxpaper.musicnet.models.complex.DeepConvNet'>\",\n",
    "    ],\n",
    "    \"stages__sparsify__model__cls\": [\n",
    "        \"<class 'cplxpaper.musicnet.models.complex.DeepConvNetVD'>\",\n",
    "        \"<class 'cplxpaper.musicnet.models.complex.DeepConvNetARD'>\",\n",
    "    ],\n",
    "    \"stages__fine-tune__model__cls\": [\n",
    "        \"<class 'cplxpaper.musicnet.models.complex.DeepConvNetMasked'>\",\n",
    "    ],\n",
    "\n",
    "    \"stages__sparsify__objective__kl_div\": kl_div_v3,\n",
    "    \"n_replication\": [*range(5)]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate manifest JSONs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "grid = ParameterGrid([\n",
    "#     grid_cplx_fine_kl_div,\n",
    "#     grid_cplx_fine_kl_div_v2,\n",
    "    grid_cplx_fine_kl_div_v3_fast,\n",
    "])\n",
    "\n",
    "PATH = os.path.abspath(os.path.join(\n",
    "    \".\", \"runs\",\n",
    "#     \"grid_cplx_fine_kl_div\"\n",
    "#     \"grid_cplx_fine_kl_div_v2\"\n",
    "    \"grid_cplx_fine_kl_div_v3_fast\"\n",
    "))\n",
    "\n",
    "os.makedirs(PATH, exist_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, par in enumerate(tqdm.tqdm(grid)):\n",
    "    param, recipe = special_params(**par)\n",
    "    param_ravel = get_params(param)\n",
    "\n",
    "    # (patch 20191224) in case frequency spec changes (very unlikely)\n",
    "    frequency = recipe.pop(\"frequency\", None)\n",
    "\n",
    "    # update the manifest\n",
    "    local = set_params(copy.deepcopy(template), **param)\n",
    "    if frequency is not None:\n",
    "        local[\"frequency\"] = frequency\n",
    "    \n",
    "    # overrides\n",
    "    local[\"device\"] = None\n",
    "    n_copy = local.pop(\"n_replication\", None)\n",
    "\n",
    "    # save\n",
    "    if n_copy is not None:\n",
    "        manifest = f\"musicnet[{n_copy:03d}]-{i:03d}.json\"\n",
    "    else:\n",
    "        manifest = f\"musicnet-{i:03d}.json\"\n",
    "\n",
    "    experiment = os.path.join(PATH, manifest)\n",
    "    if not dry_run:\n",
    "        json.dump(local, open(experiment, \"w\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
