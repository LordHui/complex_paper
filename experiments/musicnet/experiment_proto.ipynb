{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import tqdm\n",
    "\n",
    "# ...\n",
    "\n",
    "[*map(tqdm.tqdm._decr_instances, list(tqdm.tqdm._instances))]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_ = torch.device(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARD penalty class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxmodule.nn.relevance.base import BaseARD\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "\n",
    "class Penalty(_Loss):\n",
    "    def __init__(self, mean):\n",
    "        super().__init__()\n",
    "        self.reduction = torch.mean if mean else torch.sum\n",
    "\n",
    "    def forward(self, module, target=None):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def named_ard_modules(module, prefix=\"\"):\n",
    "    for name, mod in module.named_modules(prefix=prefix):\n",
    "        if isinstance(mod, BaseARD):\n",
    "            yield name, mod\n",
    "\n",
    "\n",
    "class ARDPenalty(Penalty):\n",
    "    def __init__(self, coef=1., mean=False):\n",
    "        super().__init__(mean=mean)\n",
    "        if isinstance(coef, float):\n",
    "            self.coef = lambda n: coef\n",
    "\n",
    "        elif isinstance(coef, dict):\n",
    "            self.coef = coef.get\n",
    "\n",
    "        elif callable(coef):\n",
    "            self.coef = coef\n",
    "\n",
    "    def forward(self, module, target=None):\n",
    "        \"\"\"Reimplements `named_penalties` with non-uniform coefficients.\"\"\"\n",
    "        # get names of variational modules and prefetch coefficients\n",
    "        submods = dict(named_ard_modules(module))\n",
    "        # names, submods = zip(*named_ard_modules(module))  # can't handle empty iterators\n",
    "        weights = (weight if weight is not None else 1.\n",
    "                   for weight in map(self.coef, submods.keys()))\n",
    "\n",
    "        # lazy-compute the weighted sum\n",
    "        return sum(weight * self.reduction(mod.penalty)\n",
    "                   for mod, weight in zip(submods.values(), weights)\n",
    "                   if weight > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test this out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedWrapper(object):\n",
    "    \"\"\"A wrapper for a dataLoader that puts batches on device on the fly.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    feed : torch.utils.data.DataLoader\n",
    "        The data loader instance to be wrapped.\n",
    "\n",
    "    **kwargs : keyword arguments\n",
    "        The keyword arguments to be passed to `torch.Tensor.to()`.\n",
    "    \"\"\"\n",
    "    def __init__(self, feed, **kwargs):\n",
    "        assert isinstance(feed, torch.utils.data.DataLoader)\n",
    "        self.feed, self.kwargs = feed, kwargs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feed)\n",
    "\n",
    "    def __iter__(self):\n",
    "        if not self.kwargs:\n",
    "            yield from iter(self.feed)\n",
    "\n",
    "        else:\n",
    "            for batch in iter(self.feed):\n",
    "                yield tuple(b.to(**self.kwargs)\n",
    "                            for b in batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from dpd.tools.delayed import DelayedKeyboardInterrupt\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "\n",
    "def fit(model, feed, optim, criterion, penalty=None, sched=None,\n",
    "        n_epochs=100, klw=1e-2, grad_clip=0., verbose=True):\n",
    "\n",
    "    model.train()\n",
    "    history, losses, abort = [], [], False\n",
    "    with tqdm.tqdm(range(n_epochs), disable=not verbose) as bar, \\\n",
    "            DelayedKeyboardInterrupt(\"ignore\") as stop:\n",
    "        for epoch in bar:\n",
    "            epoch_loss, kl_d, grad_norm = [], 0., float(\"nan\")\n",
    "            for j, (data, target) in zip(range(1000), feed):\n",
    "                optim.zero_grad()\n",
    "\n",
    "                crit = criterion(model(data), target)\n",
    "                if penalty is not None:\n",
    "                    kl_d = penalty(model)\n",
    "                loss = crit + klw * kl_d\n",
    "\n",
    "                loss.backward()\n",
    "                if grad_clip > 0:\n",
    "                    grad_norm = clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "                optim.step()\n",
    "                if verbose:\n",
    "                    bar.set_postfix_str(\n",
    "                        f\"{float(crit):.3e} {float(kl_d):.3e} |g| {grad_norm:.1e}\"\n",
    "                    )\n",
    "\n",
    "                history.append((float(crit), float(kl_d)))\n",
    "                epoch_loss.append(float(loss))\n",
    "\n",
    "                # abort on nan -- no need to waste compute\n",
    "                abort = np.isnan(epoch_loss[-1])\n",
    "                if abort or stop:\n",
    "                    break\n",
    "\n",
    "            if abort or stop:\n",
    "                break\n",
    "\n",
    "            if sched is not None:\n",
    "                # exclusions to `.step` api only apply to ReduceLROnPlateau\n",
    "                if isinstance(sched, ReduceLROnPlateau):\n",
    "                    sched.step(np.mean(epoch_loss))\n",
    "                else:\n",
    "                    sched.step()\n",
    "        # end for\n",
    "    # end with\n",
    "\n",
    "    return model.eval(), history, abort or stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, feed):\n",
    "    model.eval()\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        return torch.cat([\n",
    "            model(X.to(device)).cpu() for X, *rest in feed\n",
    "        ], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.musicnet.trabelsi2017 import TwoLayerDense\n",
    "from cplxpaper.musicnet.trabelsi2017.extensions import TwoLayerDenseARD\n",
    "from cplxpaper.musicnet.trabelsi2017.extensions import TwoLayerDenseMasked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.musicnet.trabelsi2017 import DeepConvNet\n",
    "from cplxpaper.musicnet.trabelsi2017.extensions import DeepConvNetARD\n",
    "from cplxpaper.musicnet.trabelsi2017.extensions import DeepConvNetMasked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 1e-3{<10}, 1e-4{<100}, 5e-5{<120}, 1e-5{<150}, 1e-6{>=150}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_lambda(epoch):\n",
    "    if epoch <  10: return 1e-0\n",
    "    if epoch < 100: return 1e-1\n",
    "    if epoch < 120: return 2e-1\n",
    "    if epoch < 150: return 1e-2\n",
    "    return 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"dense\": TwoLayerDense(),\n",
    "    \"bayes\": TwoLayerDenseARD(),  # (imbalanced) AP 12% compression 15.2%\n",
    "    \"masked\": TwoLayerDenseMasked()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"dense\": DeepConvNet(),\n",
    "    \"bayes\": DeepConvNetARD(),\n",
    "    \"masked\": DeepConvNetMasked()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from cplxpaper.musicnet import MusicNetHDF5\n",
    "\n",
    "h5_in = h5py.File(\"./data/musicnet_11khz_train.h5\", \"r\")\n",
    "dataset = MusicNetHDF5(h5_in, resident=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def get_note_dur(dataset):\n",
    "    lab = dataset[\"labels\"]\n",
    "    note_id = lab[\"note_id\"] - 21\n",
    "    duration = lab[\"end_time\"] - lab[\"start_time\"]\n",
    "\n",
    "    f_samples = float(len(dataset[\"data\"]))\n",
    "    return note_id, duration / f_samples\n",
    "\n",
    "note_durs = (get_note_dur(h5_in[f\"{key}\"]) for key in tqdm.tqdm(h5_in))\n",
    "notes, durs = map(np.concatenate, zip(*note_durs))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is imbalanced: some musical notes occur more frequently than others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def note_proba(dataset):\n",
    "    \"\"\"Estimate the probability of a musical note playing at\n",
    "    a random time within the composition.\n",
    "    \"\"\"\n",
    "    labels, n_samples = dataset[\"labels\"], len(dataset[\"data\"])\n",
    "    durations = labels[\"end_time\"] - labels[\"start_time\"]\n",
    "\n",
    "    total_duration = np.bincount(labels[\"note_id\"] - 21, weights=durations, minlength=84)\n",
    "    return total_duration / float(n_samples)\n",
    "\n",
    "train_proba = np.stack(list(map(note_proba, tqdm.tqdm(h5_in.values()))), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average probability across all 321 compositions. Clamp to prevent saturation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_hat = train_proba.mean(axis=1).clip(1e-6, 1 - 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly we need to rebalance labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given $n_-$ negative and $n_+$ positive samples, the desired balance\n",
    "$\\alpha$ and average weight $w$, chose weights $w_-$ and $w_+$ such\n",
    "that:\n",
    "$$\n",
    "w_- n_- + w_+ n_+ = w m\n",
    "    \\,,\n",
    "    n_+ w_+ = \\alpha n_- w_-\n",
    "    \\,. $$\n",
    "\n",
    "Therefore\n",
    "$$\n",
    "w_- = \\frac{w m}{n_-} \\frac1{1 + \\alpha}\n",
    "    \\,,\n",
    "    w_+ = \\frac{w m}{n_+} \\frac{\\alpha}{1 + \\alpha}\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $w_-$ is fixed to $1$, then\n",
    "$$\n",
    "w_+\n",
    "    = \\alpha \\frac{n_-}{n_+}\n",
    "    = \\alpha \\biggl( \\frac{m}{n_+} - 1\\biggr)\n",
    "    = \\alpha \\frac{1-p_+}{p_+}\n",
    "    \\,. $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logit\n",
    "\n",
    "alpha = 0.5  # 2:1 neg-pos balance\n",
    "\n",
    "pos_weight = np.exp(-logit(proba_hat)) * alpha\n",
    "\n",
    "pos_weight_clip = pos_weight.clip(max=1e2)  # clip weights to avoid overflows\n",
    "\n",
    "tr_pos_weight = torch.from_numpy(pos_weight_clip).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at them smiles and grins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 3))\n",
    "\n",
    "ax[0].semilogy(pos_weight)\n",
    "ax[0].semilogy(pos_weight_clip)\n",
    "\n",
    "ax[1].plot(proba_hat * pos_weight_clip)\n",
    "ax[1].set_ylim(-0.05)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train feed with fft features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fftpack import fft\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "\n",
    "def fft_collate_fn(batch):\n",
    "    data, target = map(np.stack, zip(*batch))\n",
    "\n",
    "    # produce features real/cplx, fft/stft/raw\n",
    "    data = fft(data, axis=-1)\n",
    "    data = np.stack([data.real, data.imag], axis=-2)\n",
    "\n",
    "    return default_collate([*zip(data, target)])\n",
    "\n",
    "feed = DataLoader(dataset, batch_size=320, shuffle=True,\n",
    "                  collate_fn=fft_collate_fn, pin_memory=True)\n",
    "feed_dev = FeedWrapper(feed, device=device_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create losses and penalties and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxmodule.nn.masked import binarize_masks\n",
    "from cplxmodule.nn.relevance import compute_ard_masks\n",
    "\n",
    "# (baseline) 98.7% compression, AP 56%\n",
    "model, threshold = None, 0.\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
    "# criterion = torch.nn.BCEWithLogitsLoss(reduction=\"mean\", pos_weight=tr_pos_weight).to(device_)\n",
    "# (try, no dense, grad_clip=0, batch 64) not that much slower than 32, AP 39% compression 95%\n",
    "\n",
    "penalty = ARDPenalty(mean=True)\n",
    "# penalty = ARDPenalty(lambda n: (1e-3 if \"conv\" in n else 1.), mean=True)\n",
    "# (try, no dense, grad_clip=0.05)  : gives 90% compression, valid-precision ~0.7-0.8\n",
    "\n",
    "histories = []\n",
    "for name, new_model in models.items():\n",
    "    print(\">>> \", name, flush=True)\n",
    "    if model is not None:\n",
    "        state_dict = model.state_dict()\n",
    "        masks = compute_ard_masks(model, threshold=threshold, hard=True)\n",
    "        state_dict, masks = binarize_masks(state_dict, masks)\n",
    "        state_dict.update(masks)\n",
    "        new_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        # (optional) crudely estimate sparsity from masks (ignores\n",
    "        #  non-dropout layers and biases)\n",
    "        if masks:\n",
    "            nnz = int(sum(map(torch.sum, masks.values())))\n",
    "            nel = int(sum(map(torch.numel, masks.values())))\n",
    "            print(f\">>> {1 - nnz / nel:4.1%}\", flush=True)\n",
    "    \n",
    "    # create stuff\n",
    "    model = new_model.to(device_)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    sched = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda)\n",
    "\n",
    "    model, history, flag = fit(model, feed_dev, optim, criterion,\n",
    "                               penalty, klw=1e-1, n_epochs=20, grad_clip=0.05)\n",
    "    # (try, no dense, grad_clip=0.05) klw=1e-3 : gives 90% compression, valid-precision ~0.6-0.7\n",
    "\n",
    "    model.cpu()\n",
    "    histories.append((name, history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from cplxpaper.auto.objective import named_ard_modules\n",
    "from ipywidgets import widgets\n",
    "\n",
    "log_alphas = {}\n",
    "with torch.no_grad():\n",
    "    for name, submod in named_ard_modules(model):\n",
    "        log_alpha = submod.log_alpha.detach().cpu()\n",
    "        log_alphas[name] = log_alpha.numpy()\n",
    "\n",
    "\n",
    "def darker(color, a=0.5):\n",
    "    \"\"\"Adapted from this stackoverflow question_.\n",
    "    .. _question: https://stackoverflow.com/questions/37765197/\n",
    "    \"\"\"\n",
    "    from matplotlib.colors import to_rgb\n",
    "    from colorsys import rgb_to_hls, hls_to_rgb\n",
    "\n",
    "    h, l, s = rgb_to_hls(*to_rgb(color))\n",
    "    return hls_to_rgb(h, max(0, min(a * l, 1)), s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if log_alphas:\n",
    "    w_keys = widgets.Dropdown(options=list(log_alphas), description=\"Layer\")\n",
    "\n",
    "    @widgets.interact(layer=w_keys)\n",
    "    def plot_hists(layer):\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(16, 5))\n",
    "        support = np.linspace(-12, 40, num=265)\n",
    "        for name, log_alpha in log_alphas.items():\n",
    "            if name != layer:\n",
    "                extra = dict(histtype=\"step\", lw=1, zorder=10)\n",
    "            else:\n",
    "                extra = dict(histtype=\"bar\", lw=0, alpha=1., zorder=-10)\n",
    "\n",
    "            *_, patches = ax.hist(log_alpha.flat, label=name, bins=51, density=True, **extra)\n",
    "            if name == layer:\n",
    "                subsample = log_alpha.flat\n",
    "                if len(subsample) > 50000:\n",
    "                    subsample = np.random.choice(subsample, replace=False, size=50000)\n",
    "                density = stats.kde.gaussian_kde(subsample)\n",
    "\n",
    "                color = darker(patches[0].get_facecolor(), 0.75)\n",
    "                ax.plot(support, density(support), c=color, lw=3, zorder=10)\n",
    "\n",
    "\n",
    "        ax.legend(ncol=2)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, history = zip(*histories)\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "crit, kl_d = map(np.array, zip(*chain(*history)))\n",
    "plt.semilogy(crit)\n",
    "plt.plot(kl_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxmodule.utils.stats import sparsity, named_sparsity\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\">>> {name:10} {sparsity(model, threshold=threshold):6.1%}\")\n",
    "\n",
    "# for name, model in models.items():\n",
    "#     print(f\">>> {name}\", [*named_sparsity(model, threshold=threshold)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_in_valid = h5py.File(\"./data/musicnet_11khz_valid.h5\", \"r\")\n",
    "dataset_valid = MusicNetHDF5(h5_in_valid, stride=128, resident=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_valid = DataLoader(dataset_valid, batch_size=256, shuffle=False,\n",
    "                        collate_fn=fft_collate_fn, pin_memory=True)\n",
    "feed_valid_dev = FeedWrapper(feed_valid, device=device_)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input, target = map(torch.cat, zip(*feed_valid_dev))\n",
    "with torch.no_grad():\n",
    "    logits = models[\"masked\"](input)\n",
    "\n",
    "logits, y_true = logits.cpu().numpy(), target.cpu().numpy().astype(np.int)\n",
    "y_pred = (logits >= 0).astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, feed):\n",
    "    model.eval()\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "#     assert False\n",
    "    with torch.no_grad():\n",
    "        return torch.cat([\n",
    "            model(X.to(device)).cpu() for X, *rest in feed\n",
    "        ], dim=0)\n",
    "\n",
    "logits = predict(models[\"bayes\"], tqdm.tqdm(feed_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.cat([target.cpu() for *rest, target in tqdm.tqdm(feed_valid)], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    logits, y_true = [], []\n",
    "    model = models[\"bayes\"].to(device_)\n",
    "    for input, target in tqdm.tqdm(feed_valid_dev):\n",
    "        logits.append(model(input).cpu().numpy())\n",
    "        y_true.append(target.cpu().numpy().astype(np.int))\n",
    "    \n",
    "    model.cpu()\n",
    "\n",
    "logits, y_true = map(np.concatenate, (logits, y_true))\n",
    "y_pred = (logits >= 0).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 3))\n",
    "\n",
    "ax[0].plot(y_true.mean(axis=0), label=\"true\")\n",
    "ax[0].plot(proba_hat, label=\"est.\")\n",
    "\n",
    "ax[1].plot(y_true.mean(axis=0) * pos_weight_clip, label=\"true\")\n",
    "ax[1].plot(proba_hat * pos_weight_clip, label=\"est.\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_cube = np.stack([\n",
    "    confusion_matrix(y_true[:, j], y_pred[:, j], labels=[0, 1])\n",
    "    for j in tqdm.tqdm(range(84))\n",
    "], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tn, fp), (fn, tp) = confusion_cube\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "precision = tp / np.maximum(tp + fp, 1)\n",
    "recall = tp / np.maximum(tp + fn, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute per-note aggregate metrics suitable for imbalanced classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, roc_auc_score\n",
    "\n",
    "average_precision = average_precision_score(\n",
    "    y_true, logits, average=None, pos_label=1)\n",
    "\n",
    "# roc_auc = roc_auc_score(y_true, logits, average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 3))\n",
    "\n",
    "ax[0].plot(average_precision, label=f\"AP {np.nanmean(average_precision):.1%}\")\n",
    "ax[0].legend(ncol=2)\n",
    "\n",
    "ax[1].plot(accuracy, label=\"acc.\")\n",
    "ax[1].plot(precision, label=\"P\")\n",
    "ax[1].plot(recall, label=\"R\")\n",
    "ax[1].legend(ncol=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pooled average precision (treatin different output as the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision_score(y_true.flat, logits.flat, average=None, pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision-recall curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 7))\n",
    "\n",
    "p, r, t = zip(*map(precision_recall_curve, y_true.T, logits.T))\n",
    "ax.add_collection(\n",
    "    LineCollection([*map(np.transpose, map(np.stack, zip(r, p)))],\n",
    "                   colors=plt.cm.PuBuGn(np.linspace(0, 1, num=len(p))),\n",
    "                   alpha=0.7)\n",
    ")\n",
    "\n",
    "p, r, t = precision_recall_curve(y_true.flat, logits.flat)\n",
    "ax.plot(r, p, c=\"k\", lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_precision.round(3)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(y_pred[3500:4000].T, cmap=plt.cm.hot)\n",
    "# ax.imshow(y_true[3500:4000].T, cmap=plt.cm.hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\beta_j$ and $c \\in \\mathbb{R}^{n\\times m}$ be parameters, then\n",
    "\n",
    "$$\n",
    "F\n",
    "  \\colon \\mathbb{R}^m \\to \\mathbb{R}^n\n",
    "  \\colon x \\mapsto \\bigl( \\beta_j \\| x - c_j \\|_2 \\bigr)_{j=1}^n\n",
    "    \\,, $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module, Parameter, init\n",
    "\n",
    "class ClusteringLayer(Module):\n",
    "    def __init__(self, in_features, out_features, p=2):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "        self.weight = Parameter(\n",
    "            torch.empty(out_features, in_features))\n",
    "        \n",
    "        self.scale = Parameter(\n",
    "            torch.empty(out_features))\n",
    "        \n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        init.kaiming_normal_(self.weight)\n",
    "        init.uniform_(self.scale, -0.01, +0.01)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        delta = input.unsqueeze(-2) - self.weight\n",
    "        return torch.norm(delta, dim=-1, p=self.p) * self.scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "class CompositeCriterion(object):\n",
    "    def __init__(self, *elements):\n",
    "        self._elements = list(elements)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{type(self).__name__}({repr(self._elements)})\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(self._elements)\n",
    "    \n",
    "    def append(self, other, coef):\n",
    "        if not isinstance(other, _Loss):\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self._elements.append((other, coef))\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if isinstance(other, CompositeCriterion):\n",
    "            return type(self)(*self, *other)\n",
    "\n",
    "        elif isinstance(other, _Loss):\n",
    "            self.append(other, 1.)\n",
    "            return self\n",
    "\n",
    "        return NotImplemented\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if isinstance(index, slice):\n",
    "            return type(self)(*self._elements[index])\n",
    "\n",
    "        return self._elements[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = CompositeCriterion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a += ARDPenalty()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.append(torch.nn.BCEWithLogitsLoss(), 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"\"\"Bad design and do not do this! A `list`, but not the list... what was i thinking?!\"\"\"\n",
    "\n",
    "from collections.abc import Iterable\n",
    "\n",
    "def as_iterable(a):\n",
    "    return a if isinstance(a, Iterable) else (a,)\n",
    "\n",
    "class CompositeCriterion(list):\n",
    "    def __new__(cls, loss=()):\n",
    "        if isinstance(loss, CompositeCriterion):\n",
    "            return loss\n",
    "        \n",
    "        return super().__new__(cls, loss)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{type(self).__name__}({super().__repr__()})\"\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return type(self)(list(self) + list(other))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ret = super().__getitem__(index)\n",
    "        if isinstance(index, slice):\n",
    "            return type(self)(ret)\n",
    "\n",
    "        return as_iterable(ret)[0]\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        return NotImplemented\n",
    "    \n",
    "    __imul__ = __mul__\n",
    "\n",
    "    def __reversed__(self):\n",
    "        return NotImplemented\n",
    "    \n",
    "    reverse = __reversed__\n",
    "    sort = __reversed__\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
