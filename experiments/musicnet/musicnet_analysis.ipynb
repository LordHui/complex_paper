{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing MusicNet exepriments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from cplxpaper.auto import auto\n",
    "from cplxpaper.auto.utils import load_snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Borrowed from mnist-like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.auto.parameter_grid import get_params\n",
    "\n",
    "def get_details(self):\n",
    "    out = dict()\n",
    "    for key in self:\n",
    "        value = self[key]\n",
    "        if isinstance(value, (dict, list, tuple)):\n",
    "            if isinstance(value, (list, tuple)):\n",
    "                value = {f\"[{i}]\": v for i, v in enumerate(value)}\n",
    "                nested = get_details(value).items()\n",
    "                out.update((key + k, val) for k, val in nested)\n",
    "\n",
    "            elif isinstance(value, dict):\n",
    "                nested = get_details(value).items()\n",
    "                out.update((key + '__' + k, val) for k, val in nested)\n",
    "\n",
    "            continue\n",
    "\n",
    "        out[key] = value\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful feed wrapper with a progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from functools import wraps\n",
    "\n",
    "from cplxpaper.auto.feeds import BaseFeedWrapper\n",
    "\n",
    "class TqdmFeed(BaseFeedWrapper):\n",
    "    @wraps(tqdm.tqdm.__init__)\n",
    "    def __init__(self, feed, **kwargs):\n",
    "        super().__init__(feed)\n",
    "        self.kwargs = kwargs\n",
    "\n",
    "    def __iter__(self):\n",
    "        with tqdm.tqdm(self.feed, **self.kwargs) as feed:\n",
    "            yield from feed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load feeds from a recent manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feeds(options, devtype):\n",
    "    return auto.get_feeds(auto.get_datasets(options[\"datasets\"]),\n",
    "                          devtype, options[\"features\"], options[\"feeds\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legacy version of the feed loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_feeds_legacy(optoons, devtype):\n",
    "    # construct datasets from pieces\n",
    "    datasets = {}\n",
    "    for name, param in options[\"dataset_sources\"].items():\n",
    "        datasets[name] = auto.get_instance(\n",
    "            **options[\"dataset\"], **param)\n",
    "\n",
    "    # get the designated batch collation function\n",
    "    collate_fn = auto.get_instance(**options[\"features\"])\n",
    "\n",
    "    # make instances of batch feeds\n",
    "    recipe = auto.param_apply_map(\n",
    "        options[\"feeds\"], dataset=datasets.__getitem__)\n",
    "\n",
    "    feeds = {}\n",
    "    for name, par in recipe.items():\n",
    "        par = auto.param_defaults(par, n_batches=-1, pin_memory=True,\n",
    "                                  cls=str(torch.utils.data.DataLoader))\n",
    "\n",
    "        max_iter = par.pop(\"n_batches\")\n",
    "        feed = get_instance(**par, collate_fn=collate_fn)\n",
    "        feeds[name] = auto.wrap_feed(feed, max_iter=max_iter, **devtype)\n",
    "\n",
    "    return feeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load model from the manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(snapshot):\n",
    "    options, stage, config = snapshot[\"options\"], *snapshot[\"stage\"]\n",
    "    model = auto.get_model(options[\"model\"], **config[\"model\"])\n",
    "    model.load_state_dict(snapshot[\"model\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.auto.utils import load_snapshot\n",
    "\n",
    "def from_snapshots(*snapshots):\n",
    "    results, options = {}, {}\n",
    "    for snapshot in sorted(snapshots):\n",
    "        name = os.path.basename(snapshot)\n",
    "        snapshot = load_snapshot(snapshot)\n",
    "\n",
    "        options = snapshot['options']\n",
    "        stage, settings = snapshot['stage']\n",
    "\n",
    "        results[name] = stage, snapshot['performance']\n",
    "\n",
    "    return results, options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_snapshot(scorers, snapshot, **devtype):\n",
    "    snapshot = load_snapshot(snapshot)\n",
    "    model = load_model(snapshot).to(**devtype)\n",
    "\n",
    "    # sad that the api was changed during the run of the experiment.\n",
    "    if \"fft-shifted\" in snapshot[\"options\"][\"features\"][\"kind\"]:\n",
    "        scorers = {name[8:]: scorer for name, scorer in scorers.items()\n",
    "                   if name.startswith(\"shifted-\")}\n",
    "    else:\n",
    "        scorers = {name: scorer for name, scorer in scorers.items()\n",
    "                   if not name.startswith(\"shifted-\")}\n",
    "    \n",
    "    scores = {name: scorer(model.eval()) for name, scorer in scorers.items()}\n",
    "\n",
    "    stored = snapshot['performance']\n",
    "    common = stored.keys() & scores.keys()\n",
    "    if stored:\n",
    "        assert common\n",
    "    for scorer_name in common:\n",
    "        original = stored[scorer_name]\n",
    "        result = scores[scorer_name]\n",
    "        for name in result.keys() & original.keys():\n",
    "            l, r = result[name], original[name]\n",
    "            assert type(l) == type(r)\n",
    "            if isinstance(l, np.ndarray):\n",
    "                assert np.allclose(l, r, equal_nan=True, atol=1e-3, rtol=2e-3)\n",
    "\n",
    "    return scores, snapshot[\"options\"]\n",
    "\n",
    "def score_snapshots(scorers, *snapshots, **devtype):\n",
    "    scores, options = {}, {}\n",
    "    for snapshot in snapshots:\n",
    "        score, options = score_snapshot(scorers, snapshot, **devtype)\n",
    "        scores[os.path.basename(snapshot)] = score\n",
    "\n",
    "    return scores, options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def score_experiment(scorers, experiment, cache=\"cache.pk\", **devtype):\n",
    "    if isinstance(cache, str):\n",
    "        cache = os.path.join(folder, cache)\n",
    "#         if os.path.isfile(cache):\n",
    "#             os.unlink(cache)\n",
    "\n",
    "    assert cache is None or isinstance(cache, str)\n",
    "\n",
    "    snapshots = []\n",
    "    experiment, _, filenames = next(os.walk(experiment))\n",
    "    for filename in filenames:\n",
    "        match = re.match(r\"^(?!\\.).*?\\.gz$\", filename)\n",
    "        if match is None or not os.path.isfile(os.path.join(experiment, filename)):\n",
    "            continue\n",
    "\n",
    "        snapshots.append(filename)\n",
    "\n",
    "    # load scorer results from the snapshots or from cache\n",
    "    scores, options = {}, {}\n",
    "    if cache is not None and os.path.exists(cache):\n",
    "        with open(cache, \"rb\") as fin:\n",
    "            scores, options = pickle.load(fin)\n",
    "\n",
    "    # reload from originals if anything is missing (use SHA-digest?)\n",
    "    if any(s not in scores for s in snapshots):\n",
    "        snapshots = [os.path.join(experiment, s) for s in snapshots]\n",
    "\n",
    "        scores, options = score_snapshots(scorers, *snapshots, **devtype)\n",
    "        if cache is not None:\n",
    "            with open(cache, \"wb\") as fout:\n",
    "                pickle.dump((scores, options), fout)\n",
    "\n",
    "    return scores, options"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to lib's version mismatch some of the runs of the musicnet\n",
    "experiment have missing pieces of performance scoring.\n",
    "\n",
    "Therefore we setup a separate pipeline to perform evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = {\n",
    "    \"datasets\": {\n",
    "        \"musicnet-test-128\": {\n",
    "          \"cls\": \"<class 'cplxpaper.musicnet.dataset.MusicNetRAM'>\",\n",
    "          \"filename\": \"/home/ivan.nazarov/Github/complex_paper/experiments/musicnet/data/musicnet_11khz_test.h5\",\n",
    "          \"window\": 4096,\n",
    "          \"stride\": 128\n",
    "        }\n",
    "    },\n",
    "    \"features\": {\n",
    "        \"cls\": \"<class 'cplxpaper.auto.feeds.FeedFourierFeatures'>\",\n",
    "        \"signal_ndim\": 1,\n",
    "        \"cplx\": True,\n",
    "        \"shift\": False\n",
    "    },\n",
    "    \"feeds\": {\n",
    "        \"test-256\": {\n",
    "            \"cls\": \"<class 'torch.utils.data.dataloader.DataLoader'>\",\n",
    "            \"dataset\": \"musicnet-test-128\",\n",
    "            \"batch_size\": 256,\n",
    "            \"pin_memory\": True,\n",
    "            \"shuffle\": False,\n",
    "            \"n_batches\": -1\n",
    "        }\n",
    "    },\n",
    "    \"scorers\": {\n",
    "        \"test_256\": {\n",
    "            \"cls\": \"<class 'cplxpaper.musicnet.performance.MusicNetBasePerformance'>\",\n",
    "            \"feed\": \"test-256\",\n",
    "            \"curves\": True\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_shifted = {\n",
    "    \"datasets\": {\n",
    "        \"musicnet-test-128\": {\n",
    "          \"cls\": \"<class 'cplxpaper.musicnet.dataset.MusicNetRAM'>\",\n",
    "          \"filename\": \"/home/ivan.nazarov/Github/complex_paper/experiments/musicnet/data/musicnet_11khz_test.h5\",\n",
    "          \"window\": 4096,\n",
    "          \"stride\": 128\n",
    "        }\n",
    "    },\n",
    "    \"features\": {\n",
    "        \"cls\": \"<class 'cplxpaper.auto.feeds.FeedFourierFeatures'>\",\n",
    "        \"signal_ndim\": 1,\n",
    "        \"cplx\": True,\n",
    "        \"shift\": True\n",
    "    },\n",
    "    \"feeds\": {\n",
    "        \"test-256\": {\n",
    "            \"cls\": \"<class 'torch.utils.data.dataloader.DataLoader'>\",\n",
    "            \"dataset\": \"musicnet-test-128\",\n",
    "            \"batch_size\": 256,\n",
    "            \"pin_memory\": True,\n",
    "            \"shuffle\": False,\n",
    "            \"n_batches\": -1\n",
    "        }\n",
    "    },\n",
    "    \"scorers\": {\n",
    "        \"shifted-test_256\": {\n",
    "            \"cls\": \"<class 'cplxpaper.musicnet.performance.MusicNetBasePerformance'>\",\n",
    "            \"feed\": \"test-256\",\n",
    "            \"curves\": True\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "res = auto.get_class(\"<class 'cplxpaper.auto.auto.get_class'>\")\n",
    "fn = res(\"<class '__main__.res'>\")\n",
    "res.__module__ + \".\" + res.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a default scorer from the pipeline manifest just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "devtype = dict(device=torch.device(\"cuda:3\"))\n",
    "\n",
    "feeds = load_feeds(pipeline, devtype)\n",
    "scorers = auto.get_scorers({\n",
    "    k: TqdmFeed(f) for k, f in feeds.items()\n",
    "}, pipeline[\"scorers\"])\n",
    "\n",
    "feeds_shifted = load_feeds(pipeline_shifted, devtype)\n",
    "scorers.update(\n",
    "    auto.get_scorers({\n",
    "        k: TqdmFeed(f) for k, f in feeds_shifted.items()\n",
    "    }, pipeline_shifted[\"scorers\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather oll MusicNet experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdir, dirnames, manifests = next(os.walk(\"./runs/grid_trabelsi\"))\n",
    "\n",
    "experiments = [m for m, e in map(os.path.splitext, manifests)\n",
    "               if e == \".json\" and os.path.isdir(os.path.join(rootdir, m))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scores = {}\n",
    "for experiment in experiments:\n",
    "    folder = os.path.join(rootdir, experiment)\n",
    "    scores[experiment] = score_experiment(scorers, folder, **devtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "ignore = {\"__name__\", \"__timestamp__\", \"__version__\", \"device\"}\n",
    "grid_options, results = defaultdict(set), []\n",
    "for experiment, (score, options) in scores.items():\n",
    "    match = re.match(r\"^.*?\\[(\\d+)\\]-(\\d+)$\", experiment)\n",
    "    replication, exp_no = map(int, match.groups())\n",
    "\n",
    "    score = {k: v[\"test_256\"] for k, v in score.items()}\n",
    "\n",
    "    flat = get_details(options)\n",
    "    for k, v in flat.items():\n",
    "        if k not in ignore:\n",
    "            grid_options[k].add(v)\n",
    "    \n",
    "    res = {}\n",
    "    for snapshot, result in score.items():\n",
    "        match = re.match(r\"^\\d+-([\\w-]+)\\s.*$\", snapshot)\n",
    "        stage, = match.groups()\n",
    "\n",
    "        n_zer, n_par = map(sum, zip(*result[\"sparsity\"].values()))\n",
    "        res[stage] = {\n",
    "            \"n_zer\": n_zer,\n",
    "            \"n_par\": n_par,\n",
    "            \"ap-score\": result[\"pooled_average_precision\"],\n",
    "#             \"ap-curve\": []\n",
    "        }\n",
    "    results.append(((exp_no, replication), res, flat))\n",
    "\n",
    "grid = [k for k, v in grid_options.items() if len(v) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cplxpaper.auto.utils import get_class\n",
    "\n",
    "cls = next(iter(grid_options[\"dataset__cls\"]))\n",
    "\n",
    "datasetname = get_class(cls).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "keys, scores, manifests = zip(*results)\n",
    "\n",
    "params = [{k: opt.get(k, None) for k in grid} for opt in manifests]\n",
    "params = pd.concat(dict(zip(keys, map(pd.Series, params))),\n",
    "                   axis=1, names=[\"expno\", \"replication\"])\n",
    "\n",
    "scores = pd.concat(dict(zip(keys, map(pd.DataFrame, scores))),\n",
    "                   axis=1, names=[\"expno\", \"replication\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = params.T.sort_index(axis=0)\n",
    "scores = scores.stack().T.swaplevel(axis=1)\n",
    "scores = scores.sort_index(axis=1).sort_index(axis=0)\n",
    "scores.columns = scores.columns.to_flat_index().map('-'.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = params.join(scores).reset_index()\n",
    "main_grid = [g for g in grid if not g.endswith('__kl_div')]\n",
    "df = df.set_index([*grid, \"expno\", \"replication\"], append=False, drop=True).sort_index(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = {}\n",
    "for k, g in df.groupby(axis=0, level=main_grid):\n",
    "    g = g.loc[k]\n",
    "\n",
    "    ap_before = g[\"dense-ap-score\"].mean(), g[\"dense-ap-score\"].std()\n",
    "\n",
    "    ap_after, n_par, n_zer = g[\"fine-tune-ap-score\"], g[\"sparsify-n_par\"], g[\"sparsify-n_zer\"]\n",
    "    curve = pd.concat([n_zer / n_par, ap_after], axis=1)\n",
    "#     curve = curve.mean(level=0).to_numpy()\n",
    "    curve = curve.to_numpy()\n",
    "    order = curve[:, 0].argsort()\n",
    "\n",
    "    summary[k] = ap_before, curve[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter, FuncFormatter\n",
    "import time\n",
    "dttm = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "figurename = os.path.basename(rootdir)\n",
    "\n",
    "filename = os.path.join(\n",
    "    os.path.dirname(os.path.abspath(rootdir)),\n",
    "    f\"{figurename} {dttm}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(14, 5))\n",
    "fig.patch.set_alpha(1.0)\n",
    "\n",
    "for name, (dense, curve) in summary.items():\n",
    "    m, s = dense\n",
    "    spr, acc = curve.T\n",
    "    pts = ax.scatter(1 - spr, acc, label=name, s=15)\n",
    "    color = pts.get_facecolor()[0]\n",
    "#     pts, = ax.plot(1 - spr, acc, label=name)\n",
    "#     color = pts.get_color()\n",
    "    ax.axhspan(m - 1.96 * s, m + 1.96 * s, alpha=0.1, color=color)\n",
    "\n",
    "ax.legend(ncol=2)\n",
    "ax.set_title(datasetname)\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "\n",
    "ax.set_xlabel(\"% nonzero\")\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlim(1e-2, 1.1)\n",
    "\n",
    "ax.xaxis.set_major_formatter(FuncFormatter(lambda x, p: f\"{x:.1%}\"))\n",
    "\n",
    "fig.savefig(filename, dpi=300, transparent=False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a mode from this specified snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"\"\"./runs/grid_trabelsi/musicnet[000]-021/\"\"\"\n",
    "!ls {folder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snapshot = load_snapshot(os.path.join(folder, \"1-sparsify 20191228-023901.gz\"))\n",
    "snapshot = load_snapshot(os.path.join(folder, \"0-dense StopIteration 20191228-110511.gz\"))\n",
    "# model = load_model(snapshot).to(**devtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot[\"early_history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = snapshot[\"performance\"][\"test_256\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = scorers['shifted-test_256'](model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in result.keys() & original.keys():\n",
    "    l, r = result[name], original[name]\n",
    "    assert type(l) == type(r)\n",
    "    if isinstance(l, np.ndarray):\n",
    "        assert np.allclose(l, r, equal_nan=True, atol=1e-3, rtol=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l - r"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
